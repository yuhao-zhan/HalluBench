#!/usr/bin/env python3
"""
Test script for the new decompose_report_to_cache function.
This script tests the paragraph decomposition and caching functionality.
"""

import json
import os
import sys

# Add the current directory to the path so we can import from evaluate
sys.path.append(os.path.dirname(os.path.abspath(__file__)))

from evaluate import decompose_report_to_cache

def test_decompose_report_to_cache():
    """Test the decompose_report_to_cache function."""
    
    # Test data
    test_query = "Test query for decomposition"
    test_report = """
    # Strategic Career Intelligence for AI PhDs: Opportunities at OpenAI, Google DeepMind, and Meta\n\n## Introduction: Navigating the Apex of the AI Job Market\n\nThe current landscape for elite Artificial Intelligence talent is one of unprecedented opportunity and intense competition. For a recent PhD graduate, this moment represents a pivotal juncture where specialized academic expertise can be translated into a role that shapes the future of technology. The epicenters of this technological revolution are, without question, OpenAI, Google DeepMind, and Meta. These organizations are not merely employers; they are the primary arenas where the boundaries of AI are being redrawn. They offer unparalleled resources, access to proprietary data and computational power, and the chance to collaborate with the field's leading minds.\n\nHowever, the allure of these institutions is matched by the ferocity of the competition to join their ranks. Securing a position requires more than a distinguished academic record; it demands strategic intelligence. This report is designed to provide precisely that. Its objective is twofold. First, it presents a curated, actionable list of currently available, PhD-appropriate roles—Research Scientist, Research Engineer, and Machine Learning Engineer—within the United States at each of these three companies. Second, and more critically, it delivers the essential strategic context needed to navigate the application process. This includes a deep analysis of each company's distinct culture, mission, team structures, and research priorities.\n\nThe job listings and analysis presented herein are based on data sourced directly from official company career portals and reputable industry aggregators as of the time of this report's composition. Direct application links are provided to facilitate verification and submission. By understanding the nuanced differences between these titans of AI, a candidate can more effectively align their personal narrative and technical skills, transforming a strong application into an irresistible one.\n\n## Section 1: The Titans of AI: A Comparative Analysis of the AI Talent Battlefield\n\nThe pursuit of top-tier AI talent has escalated into a strategic conflict among the industry's most powerful players. This \"talent war\" is not merely about accumulating headcount; it is a battle for the intellectual capital that will define the next generation of artificial intelligence. Understanding the dynamics of this competition, along with the deep-seated philosophical and structural differences between OpenAI, Google DeepMind, and Meta, is the first step in crafting a targeted career strategy.\n\n### The Great Talent War\n\nThe competition for AI expertise is most visible in the aggressive recruitment strategies being deployed. Meta, in particular, has engaged in a high-profile campaign to attract leading researchers from its primary rivals. The recent hiring of Jason Wei and Hyung Won Chun, both top researchers from OpenAI, exemplifies this trend.[[1]](https://www.ziprecruiter.com/Jobs/Deepmind-Google/--in-California) Their expertise is highly specific and strategic; Wei was a key figure in Google's \"chain-of-thought\" research and became deeply involved in reinforcement learning at OpenAI, while Chun's work focused on reasoning and agents.[[1]](https://www.ziprecruiter.com/Jobs/Deepmind-Google/--in-California) By hiring them, Meta is not just acquiring talent but systematically targeting the core research domains that have given its competitors an edge. This indicates a clear strategy to build a \"superintelligence\" team by absorbing specialists from the most advanced labs.\n\nThis aggressive hiring has significant ripple effects that impact the internal culture and compensation structures across the industry. As noted by Dell CEO Michael Dell, offering exceptionally high salaries to attract external talent can create cultural challenges and dissatisfaction among existing employees.[[1]](https://www.ziprecruiter.com/Jobs/Deepmind-Google/--in-California) For a prospective candidate, this dynamic presents both an opportunity and a caution. The opportunity lies in the potential for highly competitive compensation packages. The caution is that one might be entering a well-resourced but potentially unsettled team environment, where new and existing employee groups may operate under different expectations and reward structures. This talent war underscores that a job offer is more than a salary; it is an entry point into a complex and rapidly evolving organizational ecosystem.\n\n### Philosophical and Structural Divides\n\nBeneath the surface of the talent war lie fundamental differences in the mission and structure of each organization, which profoundly shape the work environment and the nature of the career paths they offer.\n\n* **OpenAI:** The organization operates under a unique \"capped-profit\" model and is governed by a nonprofit board.[[2]](https://www.google.com/about/careers/applications/jobs/results?q=machine+learning) Its stated mission is to ensure that artificial general intelligence (AGI) benefits all of humanity, a goal intended to subordinate profit motives to safety and societal benefit.[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) This structure attracts individuals who are deeply aligned with this specific mission and are motivated by the pursuit of AGI as a scientific and philosophical grand challenge.\n* **Google DeepMind:** Positioned as a research powerhouse within the larger Alphabet conglomerate, DeepMind has a dual mandate. It is tasked with conducting pioneering, fundamental research that pushes the boundaries of AI theory, exemplified by breakthroughs like AlphaFold.[[4]](https://deepmind.google/about/careers/) Simultaneously, it is expected to integrate its discoveries into Google's vast ecosystem of products, from Search to Cloud, thereby impacting billions of users.[[4]](https://deepmind.google/about/careers/) This creates a hybrid culture that blends the rigor of academic inquiry with the immense scale and engineering challenges of a global technology giant.\n* **Meta AI:** Meta's approach is unabashedly product-centric, with its AI development aimed at building the \"next evolution in social technology\".[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) Its strategy has become increasingly defined by the open-sourcing of powerful models, most notably the Llama family of large language models.[[7]](https://aijobs.ai/company/meta?page=2) This approach seeks to build a global developer community and create a competitive moat through ecosystem adoption rather than proprietary secrets. For a researcher at Meta, impact is often measured by the successful integration of AI into consumer-facing products or the widespread adoption of their open-source contributions.\n\n### The Strategic Divergence in Public Engagement\n\nThe three companies have adopted fundamentally different strategies regarding how they engage with the broader research community and the public, a factor that directly influences the day-to-day work and the modality of a researcher's impact.\n\nMeta's strategy can be seen as leveraging openness as a competitive tool. By releasing powerful foundation models like Llama into the open-source domain, Meta aims to commoditize the model layer of the AI stack where competitors like OpenAI have established a strong commercial lead.[[7]](https://aijobs.ai/company/meta?page=2) This fosters a broad ecosystem of developers and businesses building on Meta's architecture, creating a powerful network effect and accelerating innovation outside the confines of its own labs.\n\nIn stark contrast, OpenAI operates on a \"deployment-driven\" research paradigm. It maintains intense secrecy around its model architectures and training methods, as reported by former employees who note the extreme compartmentalization within the company.[[8]](https://openai.com/about/) However, it simultaneously releases powerful products like ChatGPT and the API Platform to the public.[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) This approach allows OpenAI to maintain its competitive advantage on the core technology while gathering invaluable data from massive, real-world usage, which in turn steers its future research directions.\n\nGoogle DeepMind pursues a hybrid strategy that bridges the worlds of academic tradition and industrial application. It continues to be a prolific publisher in top-tier scientific conferences and journals, which is essential for maintaining its esteemed reputation and attracting talent from academia.[[4]](https://deepmind.google/about/careers/) At the same time, it is deeply involved in developing and improving flagship Google products like the Gemini family of models.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) This dual focus allows it to satisfy the academic drive for open scientific inquiry and the commercial imperative of its parent company, Alphabet.\n\nUltimately, a PhD candidate must consider which modality of impact is most appealing. The choice is not merely about a research topic, but about the primary channel through which one's work will influence the world: by publishing papers and contributing to scientific knowledge, by building and nurturing an open-source community, or by deploying cutting-edge technology to millions of users through a closed, product-centric ecosystem. Each company offers a distinct path.\n\n## Section 2: Opportunities at OpenAI: Forging AGI with Intense Focus\n\nOpenAI stands apart for its singular, unwavering focus on achieving artificial general intelligence. This mission permeates every aspect of its culture, creating a work environment that is both exhilarating and exceptionally demanding. For a candidate to succeed, they must not only possess world-class technical skills but also resonate with the company's unique operational philosophy.\n\n### Strategic & Cultural Context: The OpenAI Way\n\nOpenAI's official mission is to \"ensure that general-purpose artificial intelligence benefits all of humanity\".[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) This is supported by a set of core values—\"Humanity first,\" \"Act with humility,\" \"Feel the AGI,\" and \"Ship joy\"—that are intended to guide its work.[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) These values signal a culture that is deeply reflective about the societal implications of its technology. The company's operating principles provide further insight into the expected work style: \"Find a way,\" \"Creativity over control,\" \"Update quickly,\" and \"Intense focus\".[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) Together, these principles paint a picture of an organization that prizes individual agency, rapid iteration, and an extraordinary level of dedication from its employees.\n\nHowever, the lived experience within OpenAI, as described by former employees, adds critical nuance to this official picture. The environment is characterized as both highly rewarding and \"exhausting,\" with 12-hour workdays and late nights considered routine during critical project sprints.[[8]](https://openai.com/about/) The culture is one of constant high performance, driven by tight deadlines and the pursuit of perfection. This intensity is a direct reflection of the \"Intense focus\" principle and is a key cultural attribute that candidates must be prepared for.\n\nA defining feature of OpenAI's internal dynamics is the paradox of high autonomy coupled with extreme secrecy. Communication is overwhelmingly conducted on Slack, with email being nearly non-existent, fostering a fast-paced, real-time flow of information.[[8]](https://openai.com/about/) At the same time, the organization is highly compartmentalized for competitive reasons, with teams often having little to no knowledge of what other groups are working on.[[8]](https://openai.com/about/) This creates an environment of \"monitored chaos,\" where employees are given significant freedom but may feel isolated from the company's broader progress.\n\n### The Demand for Self-Directed Researchers\n\nThe unique combination of an intense work pace, a high degree of individual autonomy, and a secretive internal environment creates a specific set of requirements for success at OpenAI. The operating principle \"Find a way\" is not merely a suggestion but a fundamental expectation.[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) It places the responsibility squarely on individuals and teams to solve problems and drive projects forward, often with minimal top-down direction.\n\nThis environment is not well-suited for researchers who require significant structure or managerial guidance. The reliance on real-time, synchronous communication via Slack favors those who can quickly process information and make decisions in a fluid, fast-moving setting.[[8]](https://openai.com/about/) The siloed nature of the teams means that a researcher cannot depend on ambient information flow to understand the larger context of their work; they must either be comfortable working with a narrow and deep focus or be exceptionally proactive in seeking out information and building cross-team relationships. A successful PhD hire at OpenAI, therefore, must be more than a brilliant scientist or engineer. They must be an entrepreneurial and resilient program manager of their own research agenda, capable of navigating ambiguity and maintaining high-velocity progress in a low-structure, high-pressure culture.\n\n### Curated Job Openings\n\nThe following table presents five open positions at OpenAI within the United States that are highly suitable for a recent PhD graduate in AI. These roles have been selected from the extensive list of over 200 openings for their direct relevance to advanced research and engineering, cutting through the noise of sales, finance, and other non-technical positions to focus on the most impactful opportunities.[[10]](https://openai.com/careers/search/?l=bbd9f7fe-aae5-476a-9108-f25aea8f6cd2) This curated list provides a clear and actionable starting point for an application strategy.\n\n| Role Title | Team / Focus Area | Location | Direct Application Link |\n| --- | --- | --- | --- |\n| Research Engineer / Research Scientist, Post-Training | Post-training | San Francisco, CA | <https://openai.com/careers/search?query=post-training> |\n| Research Engineer/Research Scientist, RL/Reasoning | Reasoning | San Francisco, CA | <https://openai.com/careers/search?query=reasoning> |\n| Machine Learning Engineer – Real-Time Multimodal Perception | Applied AI | San Francisco, CA | <https://openai.com/careers/search?query=multimodal%20perception> |\n| Research Engineer, Robotics | New Product Explorations | San Francisco, CA | <https://openai.com/careers/search?query=robotics> |\n| Distributed Training Engineer, Sora | Sora | San Francisco, CA | <https://openai.com/careers/search?query=sora> |\n\n导出到 Google 表格\n\n### Role Analysis & Suitability\n\nA closer examination of these roles reveals the strategic priorities of OpenAI and offers clear pathways for a PhD graduate to contribute.\n\n* **Research Engineer / Research Scientist, Post-Training:** The Post-training team is central to refining the behavior of foundation models. This role involves developing and implementing techniques like Reinforcement Learning from Human Feedback (RLHF), instruction tuning, and constitutional AI to make models more helpful, harmless, and honest.[[10]](https://openai.com/careers/search/?l=bbd9f7fe-aae5-476a-9108-f25aea8f6cd2) A PhD with a dissertation in reinforcement learning, alignment, or human-AI interaction would be an ideal fit for this team, which sits at the critical final stage of model development.\n* **Research Engineer/Research Scientist, RL/Reasoning:** This position is on the Reasoning team, which tackles one of the most fundamental and difficult challenges in the pursuit of AGI.[[10]](https://openai.com/careers/search/?l=bbd9f7fe-aae5-476a-9108-f25aea8f6cd2) The work likely involves developing novel architectures and algorithms to enable models to perform complex, multi-step reasoning, akin to the chain-of-thought research pioneered by talent now at competitors.[[1]](https://www.ziprecruiter.com/Jobs/Deepmind-Google/--in-California) This is a role at the absolute frontier of AI science, suited for a candidate with a deep theoretical background and a desire to work on high-risk, high-reward problems.\n* **Machine Learning Engineer – Real-Time Multimodal Perception:** This is an Applied AI role that bridges the gap between fundamental research and tangible, interactive systems.[[11]](https://openai.com/careers/) The focus on \"real-time\" and \"multimodal\" perception suggests work on robotics or other agents that need to understand and react to their environment using vision, audio, and other sensory inputs. This position is perfect for a PhD whose work involved practical application and systems building, particularly in computer vision or sensor fusion.\n* **Research Engineer, Robotics:** Situated within the \"New Product Explorations\" group, this role signals OpenAI's investment in developing the next generation of embodied intelligence.[[10]](https://openai.com/careers/search/?l=bbd9f7fe-aae5-476a-9108-f25aea8f6cd2) Unlike a purely academic robotics lab, the focus here is likely on creating scalable, general-purpose robotic systems powered by large models. A candidate with a PhD in robot learning, control theory, or simulation would find a compelling opportunity here to work on cutting-edge hardware and software.\n* **Distributed Training Engineer, Sora:** The Sora team is responsible for OpenAI's groundbreaking text-to-video model. This engineering role is not about model design but about building and optimizing the massive-scale distributed systems required to train such a model.[[11]](https://openai.com/careers/) It is a deeply technical challenge, requiring expertise in GPU kernels, networking, and large-scale infrastructure. This position is ideal for a PhD with a computational focus, perhaps in high-performance computing or systems for machine learning, who wants to work on some of the largest training runs in the world.\n\n## Section 3: Opportunities at Google DeepMind: Pioneering Science at Scale\n\nGoogle DeepMind occupies a unique and powerful position in the AI landscape. As a semi-autonomous research organization within the vast Alphabet conglomerate, it commands immense resources and a direct line of sight to product impact on a global scale. Its culture is a distinctive blend of academic rigor and industrial-strength engineering, offering a compelling environment for researchers who wish to pursue fundamental science while also solving real-world problems.\n\n### Strategic & Cultural Context: The Google Integration\n\nDeepMind operates under a dual mandate that defines its strategic direction. Its primary mission is to \"push the boundaries of artificial intelligence,\" engaging in fundamental, long-term research across a remarkable breadth of domains.[[4]](https://deepmind.google/about/careers/) This includes foundational work in algorithms and theory, as well as pioneering applications in science, such as the AlphaFold project for protein structure prediction and GNoME for materials discovery.[[4]](https://deepmind.google/about/careers/) This commitment to basic science makes it a highly attractive destination for PhDs trained in the academic tradition of inquiry and publication.\n\nSimultaneously, DeepMind is tasked with deploying its state-of-the-art research into Google's products, a responsibility that has become more pronounced with the development of the Gemini family of models.[[4]](https://deepmind.google/about/careers/) This integration provides a pathway for research to directly influence products used by billions of people, offering a scale of impact that is difficult to match elsewhere. This dual focus requires a close collaboration between research scientists and a large contingent of engineers who \"build the foundations of scalable, responsible AI research\".[[4]](https://deepmind.google/about/careers/) This highlights that DeepMind offers rich career paths not only for pure scientists but also for engineers who are passionate about building the complex, large-scale systems that modern AI research depends on.\n\nIt is also important to note that the organizational lines between the original DeepMind, Google Research, and other AI teams within Google are becoming increasingly fluid. Job postings often refer to consideration for positions across all of \"Google's research teams including Google DeepMind, Google Research\".[[13]](https://timesofindia.indiatimes.com/technology/tech-news/meta-hires-two-more-openai-top-researchers-amid-300-million-ai-talent-war-report/articleshow/122567069.cms) This suggests that while a candidate may apply with DeepMind in mind, they are entering a broader ecosystem where talent and projects are shared across different groups.\n\n### The Primacy of the Team in a DeepMind Application\n\nGiven the immense scale of Google and the porous boundaries between its various research divisions, the single most critical factor for a prospective candidate to consider is the specific team they are targeting. The day-to-day work, research agenda, and culture can vary significantly from one team to another, making the team choice a more important determinant of the experience than the overarching \"Google DeepMind\" brand.\n\nDeepMind's career portal reflects this reality, with job openings listed under highly descriptive and mission-oriented team names. There are fundamental research teams like \"Training Algorithms\" and \"World Modeling,\" applied teams like \"Applied Robotics,\" and safety-focused groups like \"Multimodal Alignment, Safety, and Fairness\".[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) Each of these names points to a distinct charter and research focus. In addition, there are product-aligned teams, such as those working on \"GeminiApp,\" which are likely to operate on different timelines and with different pressures than a long-term, fundamental research group.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427)\n\nThis team-centric structure is not unique to DeepMind but is a feature of all top-tier labs. A PhD candidate should therefore move beyond the general goal of \"working at DeepMind\" and instead conduct deep diligence on the specific teams that align with their expertise. The application materials—from the CV to the cover letter—should be meticulously tailored to the stated goals and recent publications of the target team. Explicitly articulating this alignment demonstrates a level of strategic thinking and genuine interest that will differentiate an application.\n\n### Curated Job Openings\n\nThe following table presents five open positions at Google DeepMind in the United States that are an excellent match for a new AI PhD. These roles have been carefully selected from the official DeepMind careers board, filtering out non-US and non-technical positions to provide a focused and relevant list.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) This curated selection serves as a strategic guide to the most promising opportunities within the vast Google/DeepMind research ecosystem.\n\n| Role Title | Team / Focus Area | Location | Direct Application Link |\n| --- | --- | --- | --- |\n| Research Engineer/Scientist, Training Algorithms | Fundamental Research | Mountain View, CA | <https://www.google.com/about/careers/applications/jobs/results/141045207314350790-research-engineerscientist-training-algorithms> |\n| Research Scientist, Multimodal Alignment, Safety, and Fairness | Responsibility and Safety | Mountain View, CA | <https://www.google.com/about/careers/applications/jobs/results/137345214539121350-research-scientist-multimodal-alignment-safety-and-fairness> |\n| Research Scientist / Engineer, World Modeling | Fundamental Research | Mountain View, CA | <https://www.google.com/about/careers/applications/jobs/results/114949182377493190-research-scientist-engineer-world-modeling> |\n| Research Engineer, Applied Robotics | Applied Research | Mountain View, CA | <https://www.google.com/about/careers/applications/jobs/results/13614016649514260-research-engineer-applied-robotics> |\n| Research Scientist, R2 | Fundamental Research | New York City, NY | <https://www.google.com/about/careers/applications/jobs/results/114949182377493190-research-scientist-r2> |\n\n导出到 Google 表格\n\n### Role Analysis & Suitability\n\nEach of these roles represents a distinct and compelling opportunity for a PhD graduate to apply their skills to frontier research problems.\n\n* **Research Engineer/Scientist, Training Algorithms:** This is a core fundamental research position focused on the very heart of how AI models learn.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) The work involves designing and experimenting with novel optimization methods, neural network architectures, and scaling laws. It is an ideal role for a candidate with a strong theoretical PhD in machine learning, optimization, or learning theory, offering a chance to contribute to the foundational science that underpins all of DeepMind's models.\n* **Research Scientist, Multimodal Alignment, Safety, and Fairness:** This role is situated within the critically important Responsibility and Safety team.[[4]](https://deepmind.google/about/careers/) As models become more powerful and multimodal, ensuring they are aligned with human values, safe to deploy, and fair in their outcomes is a paramount challenge. This position is perfectly suited for a candidate whose doctoral research touched on AI ethics, interpretability, robustness, or bias, placing them at the intersection of technology and society.\n* **Research Scientist / Engineer, World Modeling:** This is a long-term, highly ambitious research area focused on building generative models that can learn to understand and simulate the physical world.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) This capability is seen as a key stepping stone toward more general intelligence. The role would be an excellent fit for a PhD with a background in reinforcement learning, generative modeling, computer vision, or physics-based simulation.\n* **Research Engineer, Applied Robotics:** Similar to roles at other top labs, this position is for a researcher who wants to work on embodied AI.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) The \"Applied\" designation suggests a focus on solving the practical challenges of making robots work reliably in complex, real-world environments. This is a compelling opportunity for a candidate with a hands-on PhD in robotics, control systems, or sim-to-real transfer.\n* **Research Scientist, R2:** While \"R2\" is likely an internal team or project designation, the existence of this fundamental research role in the New York City office is significant.[[9]](https://boards.greenhouse.io/deepmind/jobs/6541427) It indicates that DeepMind's core research efforts are not confined to its California headquarters, offering a top-tier research opportunity in a different major US tech hub.\n\n## Section 4: Opportunities at Meta AI: Building the Open Future of AI\n\nMeta's approach to artificial intelligence is characterized by its deep integration with product development and an increasingly bold strategy centered on open-source innovation. For a PhD graduate, Meta offers the opportunity to see their research rapidly deployed in products that touch billions of lives and to contribute to a global, collaborative ecosystem that is reshaping the competitive dynamics of the AI industry.\n\n### Strategic & Cultural Context: Product-Driven and Open\n\nMeta's overarching mission is to leverage AI to \"build the next evolution in social technology,\" moving beyond 2D screens toward immersive experiences.[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) This product-centric vision drives its AI research agenda. The company's flagship AI projects are tangible and consumer-facing: the Llama family of open-source large language models, the conversational Meta AI assistant integrated across its apps, and AI-infused hardware like the Ray-Ban Meta glasses.[[7]](https://aijobs.ai/company/meta?page=2)\n\nA defining feature of Meta's current strategy is its profound commitment to open-source.[[7]](https://aijobs.ai/company/meta?page=2) By releasing powerful models like Llama 3.1, Meta is not only sharing its technology but also fostering a global community of developers and researchers who can use, scrutinize, and improve upon its work. This approach accelerates innovation, promotes transparency, and serves as a powerful competitive strategy against companies with closed-model ecosystems. For a researcher at Meta, this means their work has the potential for broad impact, both within Meta's products and across the wider AI community.\n\nThe key organizational units for a prospective AI PhD are the Fundamental AI Research (FAIR) team, which focuses on long-term, breakthrough science; the Generative AI group, which leads the development of Llama and other generative models; and Meta Reality Labs, which is dedicated to the AR/VR technologies that will underpin the metaverse.[[7]](https://aijobs.ai/company/meta?page=2) The company's aggressive talent acquisition, marked by high-profile hires from competitors, indicates a willingness to invest heavily to build world-class teams in these areas, creating an environment of high expectations and substantial resources for new hires.[[1]](https://www.ziprecruiter.com/Jobs/Deepmind-Google/--in-California)\n\n### Location as an Indicator of Team Focus\n\nUnlike the highly centralized nature of OpenAI's research operations, Meta's AI teams are geographically distributed across several major US tech hubs. This distribution is not random; the location of a job opening often serves as a strong signal about the specific focus of the team and its projects.\n\nAn analysis of Meta's career postings reveals clear patterns. For instance, the \"AI Research Scientist - Computer Vision\" role lists locations such as Pittsburgh, PA; Redmond, WA; and Burlingame, CA.[[17]](https://www.metacareers.com/jobs/1349554602780483) These cities are established hubs for Meta Reality Labs (which grew out of Oculus Research), strongly suggesting that roles in these locations are tied to research in computer vision, human understanding, and perception for AR/VR applications. In contrast, roles related to large language models and speech, such as the \"AI Research Scientist, Language\" and \"Research Scientist, Speech & Audio\" positions, are often based in major corporate and software engineering hubs like Menlo Park, CA; Seattle, WA; and New York, NY.[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) This suggests these roles are more closely aligned with core software products like the Meta AI assistant or content understanding for platforms like Instagram and Facebook. A candidate can therefore use location as a strategic filter, prioritizing applications in cities that align with their specific research interests—be it embodied AI for the metaverse or large-scale language modeling for social platforms.\n\n### Curated Job Openings\n\nThe following table presents five open positions at Meta AI across the United States that are an excellent fit for a recent AI PhD. These roles have been meticulously selected from Meta's official careers portal, filtering out a large number of unrelated positions to focus on the most relevant and high-impact research opportunities.[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) The table highlights the variety of research areas and geographic locations available, providing a strategic map for a targeted job search.\n\n| Role Title | Team / Focus Area | Locations | Direct Application Link |\n| --- | --- | --- | --- |\n| AI Research Scientist, Language - Generative AI | Llama LLM Research | Bellevue, WA; Menlo Park, CA; Seattle, WA; New York, NY | <https://www.metacareers.com/jobs/1014936436926274/> |\n| AI Research Scientist (Robotics) | Fundamental AI Research (FAIR) | Burlingame, CA; Menlo Park, CA; New York, NY; Pittsburgh, PA; Redmond, WA; Seattle, WA | <https://www.metacareers.com/jobs/1024912282791680/> |\n| AI Research Scientist - Computer Vision | Meta Reality Labs | Pittsburgh, PA; Redmond, WA; Burlingame, CA | <https://www.metacareers.com/jobs/782606810425134/> |\n| Research Scientist, Speech & Audio - Generative AI (PhD) | AGI Multimedia | Menlo Park, CA; Seattle, WA; New York, NY | <https://www.metacareers.com/jobs/726171350569593/> |\n| Research Scientist, AI for Science (PhD) | FAIR - Chemistry | San Francisco, CA | <https://www.metacareers.com/jobs/1349554602780483/> |\n\n导出到 Google 表格\n\n### Role Analysis & Suitability\n\nEach of these positions offers a unique opportunity to contribute to Meta's ambitious AI goals.\n\n* **AI Research Scientist, Language - Generative AI:** This role is on the flagship Llama team, placing a researcher at the heart of Meta's open-source strategy.[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) The team seeks experts in NLP and reinforcement learning to work on critical areas like LLM alignment, multilingual modeling, and code generation. It is a perfect opportunity for a PhD in these fields to contribute to one of the world's most influential large language models.\n* **AI Research Scientist (Robotics):** This is a fundamental research role within the prestigious FAIR team, focused on making long-term breakthroughs in embodied intelligence.[[16]](https://www.metacareers.com/jobs/782606810425134) The research areas are ambitious, including learning from demonstration, sim-to-real transfer, and dexterous manipulation. This position is ideal for a candidate with a research-heavy PhD who wants to push the scientific frontier of robotics and publish in top-tier venues.\n* **AI Research Scientist - Computer Vision:** This role is explicitly tied to Meta Reality Labs and the future of AR/VR.[[17]](https://www.metacareers.com/jobs/1349554602780483) The work involves advancing the state-of-the-art in human understanding, action recognition, and perception to enable intuitive and seamless human-computer interaction on next-generation hardware. It is an excellent fit for a PhD in computer vision who is passionate about creating the foundational technologies for the metaverse.\n* **Research Scientist, Speech & Audio - Generative AI (PhD):** Situated within the \"AGI Multimedia\" pillar, this role focuses on building foundation models for audio understanding and generation.[[18]](https://www.metacareers.com/jobs/1024912282791680) This is a rapidly growing field with applications in text-to-speech, music generation, and creating richer, more interactive virtual experiences. A candidate with a PhD in speech processing, TTS, or audio representation learning would be highly sought after for this team.\n* **Research Scientist, AI for Science (PhD):** This is a highly specialized role within FAIR's Chemistry team, demonstrating Meta's investment in applying AI to fundamental scientific discovery.[[19]](https://www.metacareers.com/jobs/726171350569593) The goal is to use AI to accelerate the discovery of new materials and molecules for applications in climate and AR/VR. This position is a unique opportunity for a PhD who has worked at the intersection of machine learning and a physical science like chemistry or materials science.\n\n## Section 5: Strategic Recommendations for the AI PhD Candidate\n\nSuccessfully securing a role at OpenAI, Google DeepMind, or Meta requires more than technical brilliance; it requires a strategic approach to positioning one's expertise. This involves decoding the nuances of job titles and meticulously tailoring the narrative of one's PhD research to align with the distinct culture and priorities of each organization.\n\n### Decoding the Titles: Scientist vs. Engineer\n\nThe titles \"Research Scientist,\" \"Research Engineer,\" and \"Machine Learning Engineer\" can have overlapping responsibilities, but they often signal different expectations and career trajectories.\n\n* **Research Scientist:** This role is typically closest to that of a principal investigator in academia. The primary expectation is to define novel research problems, lead projects from conception to publication, and advance the state of the art in a given field. A strong publication record, particularly first-author papers at top-tier conferences like NeurIPS, ICML, and CVPR, is often a key requirement.[[6]](https://timesofindia.indiatimes.com/education/news/what-its-really-like-to-work-at-openai-no-emails-12-hour-days-and-the-push-for-perfection/articleshow/122620842.cms) This role is best suited for individuals who wish to focus on scientific inquiry and discovery.\n* **Research Engineer:** This position is a hybrid role that combines deep machine learning knowledge with strong software engineering skills. Research Engineers are the architects of the experimental process; they build the models, design the large-scale experiments, and create the infrastructure necessary to test research hypotheses.[[4]](https://deepmind.google/about/careers/) They work in close partnership with Research Scientists to turn ideas into demonstrable results. This role is ideal for a candidate who excels at both theoretical understanding and practical implementation.\n* **Machine Learning Engineer:** At these elite labs, this title often refers to a highly specialized engineer focused on the challenges of scale, optimization, and deployment.[[11]](https://openai.com/careers/) Their work might involve optimizing GPU kernel performance, building robust data pipelines for massive datasets, or developing the systems for deploying models to millions of users. While deeply technical, this role can be more product-proximate than a Research Engineer position.\n\nA candidate should analyze job descriptions with care. The responsibilities of a \"Research Engineer\" at OpenAI, with its emphasis on autonomy, might be more research-driven than those of an \"ML Engineer\" at a more product-focused group within Google. The specific team's mission and recent output are often the most reliable guides to the true nature of a role.\n\n### Tailoring Your Narrative: From PhD Thesis to Industry Value\n\nA generic application is unlikely to succeed. The candidate's narrative must be reshaped to resonate with the specific values and language of each target company.\n\n* **For OpenAI:** The application narrative should emphasize qualities of self-direction, resilience, and an \"intense focus\".[[3]](https://www.ziprecruiter.com/Jobs/Deepmind-Google) Frame the PhD research not just as a technical contribution but as a step toward solving a grand challenge, aligning it with OpenAI's mission of building safe AGI. Highlight projects that required significant personal initiative, where the candidate had to \"find a way\" through ambiguous or unstructured problems. Showcase a passion for the mission itself.\n* **For Google DeepMind:** The narrative should highlight scientific rigor and a track record of impactful research contributions, evidenced by publications. It is crucial to connect the doctoral work to one of DeepMind's major research pillars, such as AI for Science, fundamental algorithms, or safety and responsibility.[[4]](https://deepmind.google/about/careers/) The candidate should demonstrate an appreciation for how fundamental discoveries can be engineered to operate at immense scale and solve real-world problems.\n* **For Meta AI:** The application should align the candidate's skills with Meta's product goals and its open-source philosophy. If the PhD involved training large models, the narrative should connect this experience to projects like Llama.[[7]](https://aijobs.ai/company/meta?page=2) If the research was in computer vision, it should be framed in the context of the future of AR/VR and Meta Reality Labs.[[17]](https://www.metacareers.com/jobs/1349554602780483) Any contributions to open-source projects should be prominently featured, as this demonstrates a direct alignment with Meta's collaborative and community-oriented strategy.\n\n### Final Checklist for the Applicant\n\nBefore submitting an application, a candidate should perform a final strategic review:\n\n* Have you researched the specific **team**, its recent publications, its leaders, and its stated mission?\n* Have you tailored your CV and cover letter to use the specific language, values, and project names of the target company and team?\n* Are you prepared to discuss not only the technical details of your research but also your work style, your approach to collaboration, and how you handle ambiguity and setbacks?\n* Have you thoughtfully considered the cultural trade-offs—OpenAI's intensity, Google's scale, Meta's product-focus—and articulated why a specific environment is the best fit for your personal and professional goals?",
    """
    
    # Test cache file path
    test_cache_file = "../json_cache/temp_test_cache.json"
    
    print("🧪 Testing decompose_report_to_cache function...")
    print(f"Query: {test_query}")
    print(f"Report length: {len(test_report)} characters")
    print(f"Cache file: {test_cache_file}")
    
    # Test the function
    try:
        result = decompose_report_to_cache(test_report, test_query, test_cache_file)
        print(f"✅ Function executed successfully. Result: {result}")
        
        # Check if cache file was created and contains the expected structure
        if os.path.exists(test_cache_file):
            with open(test_cache_file, 'r', encoding='utf-8') as f:
                cache_data = json.load(f)
            
            print(f"📁 Cache file created successfully")
            print(f"📊 Cache structure: {list(cache_data.keys())}")
            
            if 'report' in cache_data:
                report_data = cache_data['report']
                print(f"📝 Report data found with {len(report_data)} paragraphs")
                
                for i, para in enumerate(report_data):
                    print(f"  Paragraph {i+1}: {len(para.get('atomic_claims', []))} claims")
                    if 'error' in para:
                        print(f"    Error: {para['error']}")
            else:
                print("❌ Report data not found in cache")
        else:
            print("❌ Cache file was not created")
            
    except Exception as e:
        print(f"❌ Error during testing: {str(e)}")
        import traceback
        traceback.print_exc()
    
    finally:
        # Clean up test file
        if os.path.exists(test_cache_file):
            os.remove(test_cache_file)
            print(f"🧹 Cleaned up test cache file: {test_cache_file}")

if __name__ == "__main__":
    print("🚀 Starting tests for decompose_report_to_cache function...")
    
    # Test 1: Basic functionality
    test_decompose_report_to_cache()
    
    print("\n🎉 All tests completed!")
