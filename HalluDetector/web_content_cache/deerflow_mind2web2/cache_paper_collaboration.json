{
  "http://nlp.csai.tsinghua.edu.cn/~msun/": "Title: \n\nURL Source: http://nlp.csai.tsinghua.edu.cn/~msun/\n\nWarning: Target URL returned error 404: Not Found\n\nMarkdown Content:\n404 Not Found\n",
  "https://arxiv.org/abs/2204.07865": "Title: Enabling Relative Localization for Nanodrone Swarm Platooning\n\nURL Source: https://arxiv.org/abs/2204.07865\n\nMarkdown Content:\n[2204.07865] Enabling Relative Localization for Nanodrone Swarm Platooning\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2204.07865#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2204.07865 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Human-Computer Interaction\n=============================================\n\n**arXiv:2204.07865** (cs) \n\n [Submitted on 16 Apr 2022]\n\nTitle:Enabling Relative Localization for Nanodrone Swarm Platooning\n===================================================================\n\nAuthors:[Wei Sun](https://arxiv.org/search/cs?searchtype=author&query=Sun,+W)\n\nView a PDF of the paper titled Enabling Relative Localization for Nanodrone Swarm Platooning, by Wei Sun\n\n[View PDF](https://arxiv.org/pdf/2204.07865)\n> Abstract:Nanodrone swarm is formulated by multiple light-weight and low-cost nanodrones to perform the tasks in very challenging environments. Therefore, it is essential to estimate the relative position of nanodrones in the swarm for accurate and safe platooning in inclement indoor environment. However, the vision and infrared sensors are constrained by the line-of-sight perception, and instrumenting extra motion sensors on drone's body is constrained by the nanodrone's form factor and energy-efficiency. \n> \n> This paper presents the design, implementation and evaluation of RFDrone, a system that can sense the relative position of nanodrone in the swarm using wireless signals, which can naturally identify each individual nanodrone. To do so, each light-weight nanodrone is attached with a RF sticker (i.e., called RFID tag), which will be localized by the external RFID reader in the inclement indoor environment. Instead of accurately localizing each RFID-tagged nanodrone, we propose to estimate the relative position of all the RFID-tagged nanodrones in the swarm based on the spatial-temporal phase profiling. We implement an end-to-end physical prototype of RFDrone. Our experimental results show that RFDrone can accurately estimate the relative position of nanodrones in the swarm with average relative localization accuracy of around 0.95 across x, y and z axis, and average accuracy of around 0.93 for nanodrone swarm's geometry estimation.\n\nSubjects:Human-Computer Interaction (cs.HC)\nCite as:[arXiv:2204.07865](https://arxiv.org/abs/2204.07865) [cs.HC]\n(or [arXiv:2204.07865v1](https://arxiv.org/abs/2204.07865v1) [cs.HC] for this version)\n[https://doi.org/10.48550/arXiv.2204.07865](https://doi.org/10.48550/arXiv.2204.07865)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Wei Sun [[view email](https://arxiv.org/show-email/3bc000d6/2204.07865)] \n\n**[v1]** Sat, 16 Apr 2022 20:18:03 UTC (3,232 KB)\n\n[](https://arxiv.org/abs/2204.07865)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled Enabling Relative Localization for Nanodrone Swarm Platooning, by Wei Sun\n\n*   [View PDF](https://arxiv.org/pdf/2204.07865)\n*   [TeX Source](https://arxiv.org/src/2204.07865)\n*   [Other Formats](https://arxiv.org/format/2204.07865)\n\n[![Image 5: license icon](https://arxiv.org/icons/licenses/by-nc-nd-4.0.png)view license](http://creativecommons.org/licenses/by-nc-nd/4.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.HC\n\n[<prev](https://arxiv.org/prevnext?id=2204.07865&function=prev&context=cs.HC \"previous in cs.HC (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2204.07865&function=next&context=cs.HC \"next in cs.HC (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.HC/new) | [recent](https://arxiv.org/list/cs.HC/recent) | [2022-04](https://arxiv.org/list/cs.HC/2022-04)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2204.07865?context=cs)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2204.07865)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2204.07865)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2204.07865)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2204.07865)\n\n### Bookmark\n\n[![Image 6: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2204.07865&description=Enabling%20Relative%20Localization%20for%20Nanodrone%20Swarm%20Platooning \"Bookmark on BibSonomy\")[![Image 7: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2204.07865&title=Enabling%20Relative%20Localization%20for%20Nanodrone%20Swarm%20Platooning \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2204.07865)\n*   [Venue](https://arxiv.org/abs/2204.07865)\n*   [Institution](https://arxiv.org/abs/2204.07865)\n*   [Topic](https://arxiv.org/abs/2204.07865)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2204.07865) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2205.04567": "Title: The Compound Information Bottleneck Outlook\n\nURL Source: https://arxiv.org/abs/2205.04567\n\nMarkdown Content:\n[2205.04567] The Compound Information Bottleneck Outlook\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2205.04567#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2205.04567 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Information Theory\n=====================================\n\n**arXiv:2205.04567** (cs) \n\n [Submitted on 9 May 2022]\n\nTitle:The Compound Information Bottleneck Outlook\n=================================================\n\nAuthors:[Michael Dikshtein](https://arxiv.org/search/cs?searchtype=author&query=Dikshtein,+M), [Nir Weinberger](https://arxiv.org/search/cs?searchtype=author&query=Weinberger,+N), [Shlomo Shamai](https://arxiv.org/search/cs?searchtype=author&query=Shamai,+S) (Shitz)\n\nView a PDF of the paper titled The Compound Information Bottleneck Outlook, by Michael Dikshtein and 2 other authors\n\n[View PDF](https://arxiv.org/pdf/2205.04567)\n> Abstract:We formulate and analyze the compound information bottleneck programming. In this problem, a Markov chain \\mathsf{X} \\rightarrow \\mathsf{Y} \\rightarrow \\mathsf{Z} is assumed with fixed marginal distributions \\mathsf{P}_{\\mathsf{X}}and \\mathsf{P}_{\\mathsf{Y}}, and the mutual information between \\mathsf{X} and \\mathsf{Z} is sought to be maximized over the choice of conditional probability of \\mathsf{Z}given \\mathsf{Y}from a given class, under the \\textit{worst choice} of the joint probability of the pair (\\mathsf{X},\\mathsf{Y})from a different class. We consider several classes based on extremes of: mutual information; minimal correlation; total variation; and the relative entropy class. We provide values, bounds, and various characterizations for specific instances of this problem: the binary symmetric case, the scalar Gaussian case, the vector Gaussian case and the symmetric modulo-additive case. Finally, for the general case, we propose a Blahut-Arimoto type of alternating iterations algorithm to find a consistent solution to this problem.\n\nComments:This work has been submitted to the IEEE for possible publication\nSubjects:Information Theory (cs.IT)\nCite as:[arXiv:2205.04567](https://arxiv.org/abs/2205.04567) [cs.IT]\n(or [arXiv:2205.04567v1](https://arxiv.org/abs/2205.04567v1) [cs.IT] for this version)\n[https://doi.org/10.48550/arXiv.2205.04567](https://doi.org/10.48550/arXiv.2205.04567)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Michael Dikshtein [[view email](https://arxiv.org/show-email/d11fff18/2205.04567)] \n\n**[v1]** Mon, 9 May 2022 21:27:45 UTC (1,502 KB)\n\n[](https://arxiv.org/abs/2205.04567)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled The Compound Information Bottleneck Outlook, by Michael Dikshtein and 2 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2205.04567)\n*   [TeX Source](https://arxiv.org/src/2205.04567)\n*   [Other Formats](https://arxiv.org/format/2205.04567)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.IT\n\n[<prev](https://arxiv.org/prevnext?id=2205.04567&function=prev&context=cs.IT \"previous in cs.IT (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2205.04567&function=next&context=cs.IT \"next in cs.IT (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.IT/new) | [recent](https://arxiv.org/list/cs.IT/recent) | [2022-05](https://arxiv.org/list/cs.IT/2022-05)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2205.04567?context=cs)\n\n[math](https://arxiv.org/abs/2205.04567?context=math)\n\n[math.IT](https://arxiv.org/abs/2205.04567?context=math.IT)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2205.04567)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2205.04567)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2205.04567)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2205.04567)\n\n### Bookmark\n\n[![Image 5: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2205.04567&description=The%20Compound%20Information%20Bottleneck%20Outlook \"Bookmark on BibSonomy\")[![Image 6: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2205.04567&title=The%20Compound%20Information%20Bottleneck%20Outlook \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2205.04567)\n*   [Venue](https://arxiv.org/abs/2205.04567)\n*   [Institution](https://arxiv.org/abs/2205.04567)\n*   [Topic](https://arxiv.org/abs/2205.04567)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2205.04567) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2206.08118": "Title: Bayesian conjugacy in probit, tobit, multinomial probit and extensions: A review and new results\n\nURL Source: https://arxiv.org/abs/2206.08118\n\nMarkdown Content:\n[2206.08118] Bayesian conjugacy in probit, tobit, multinomial probit and extensions: A review and new results\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2206.08118#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[stat](https://arxiv.org/list/stat/recent)> arXiv:2206.08118 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nStatistics > Methodology\n========================\n\n**arXiv:2206.08118** (stat) \n\n [Submitted on 16 Jun 2022 ([v1](https://arxiv.org/abs/2206.08118v1)), last revised 5 Mar 2023 (this version, v3)]\n\nTitle:Bayesian conjugacy in probit, tobit, multinomial probit and extensions: A review and new results\n======================================================================================================\n\nAuthors:[Niccolò Anceschi](https://arxiv.org/search/stat?searchtype=author&query=Anceschi,+N), [Augusto Fasano](https://arxiv.org/search/stat?searchtype=author&query=Fasano,+A), [Daniele Durante](https://arxiv.org/search/stat?searchtype=author&query=Durante,+D), [Giacomo Zanella](https://arxiv.org/search/stat?searchtype=author&query=Zanella,+G)\n\nView a PDF of the paper titled Bayesian conjugacy in probit, tobit, multinomial probit and extensions: A review and new results, by Niccol\\`o Anceschi and 3 other authors\n\n[View PDF](https://arxiv.org/pdf/2206.08118)\n> Abstract:A broad class of models that routinely appear in several fields can be expressed as partially or fully discretized Gaussian linear regressions. Besides including basic Gaussian response settings, this class also encompasses probit, multinomial probit and tobit regression, among others, thereby yielding to one of the most widely-implemented families of models in applications. The relevance of such representations has stimulated decades of research in the Bayesian field, mostly motivated by the fact that, unlike for Gaussian linear regression, the posterior distribution induced by such models does not seem to belong to a known class, under the commonly-assumed Gaussian priors for the coefficients. This has motivated several solutions for posterior inference relying on sampling-based strategies or on deterministic approximations that, however, still experience computational and accuracy issues, especially in high dimensions. The scope of this article is to review, unify and extend recent advances in Bayesian inference and computation for this class of models. To address such a goal, we prove that the likelihoods induced by these formulations share a common analytical structure that implies conjugacy with a broad class of distributions, namely the unified skew-normals (SUN), that generalize Gaussians to skewed contexts. This result unifies and extends recent conjugacy properties for specific models within the class analyzed, and opens avenues for improved posterior inference, under a broader class of formulations and priors, via novel closed-form expressions, i.i.d. samplers from the exact SUN posteriors, and more accurate and scalable approximations from VB and EP. Such advantages are illustrated in simulations and are expected to facilitate the routine-use of these core Bayesian models, while providing a novel framework to study theoretical properties and develop future extensions.\n\nSubjects:Methodology (stat.ME); Computation (stat.CO)\nCite as:[arXiv:2206.08118](https://arxiv.org/abs/2206.08118) [stat.ME]\n(or [arXiv:2206.08118v3](https://arxiv.org/abs/2206.08118v3) [stat.ME] for this version)\n[https://doi.org/10.48550/arXiv.2206.08118](https://doi.org/10.48550/arXiv.2206.08118)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Niccolò Anceschi Mr [[view email](https://arxiv.org/show-email/430b01fe/2206.08118)] \n\n**[[v1]](https://arxiv.org/abs/2206.08118v1)** Thu, 16 Jun 2022 12:24:27 UTC (82 KB)\n\n**[[v2]](https://arxiv.org/abs/2206.08118v2)** Thu, 12 Jan 2023 13:33:42 UTC (762 KB)\n\n**[v3]** Sun, 5 Mar 2023 19:37:20 UTC (765 KB)\n\n[](https://arxiv.org/abs/2206.08118)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled Bayesian conjugacy in probit, tobit, multinomial probit and extensions: A review and new results, by Niccol\\`o Anceschi and 3 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2206.08118)\n*   [TeX Source](https://arxiv.org/src/2206.08118)\n*   [Other Formats](https://arxiv.org/format/2206.08118)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \"Rights to this article\")\n\n Current browse context: \n\nstat.ME\n\n[<prev](https://arxiv.org/prevnext?id=2206.08118&function=prev&context=stat.ME \"previous in stat.ME (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2206.08118&function=next&context=stat.ME \"next in stat.ME (accesskey n)\")\n\n[new](https://arxiv.org/list/stat.ME/new) | [recent](https://arxiv.org/list/stat.ME/recent) | [2022-06](https://arxiv.org/list/stat.ME/2022-06)\n\n Change to browse by: \n\n[stat](https://arxiv.org/abs/2206.08118?context=stat)\n\n[stat.CO](https://arxiv.org/abs/2206.08118?context=stat.CO)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2206.08118)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2206.08118)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2206.08118)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2206.08118)\n\n### Bookmark\n\n[![Image 5: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2206.08118&description=Bayesian%20conjugacy%20in%20probit,%20tobit,%20multinomial%20probit%20and%20extensions:%20A%20review%20and%20new%20results \"Bookmark on BibSonomy\")[![Image 6: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2206.08118&title=Bayesian%20conjugacy%20in%20probit,%20tobit,%20multinomial%20probit%20and%20extensions:%20A%20review%20and%20new%20results \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2206.08118)\n*   [Venue](https://arxiv.org/abs/2206.08118)\n*   [Institution](https://arxiv.org/abs/2206.08118)\n*   [Topic](https://arxiv.org/abs/2206.08118)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2206.08118) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2207.06899": "Title: Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation\n\nURL Source: https://arxiv.org/abs/2207.06899\n\nMarkdown Content:\n[2207.06899] Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation\n\n===============\n[![Image 1: close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](https://arxiv.org/abs/2207.06899#)\n\n![Image 2: arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n\nHappy Birthday to arXiv!\n------------------------\n\nIt's our birthday — woohoo! On August 14th, 1991, the very first paper was submitted to arXiv. That's 34 years of open science! Give today and help support arXiv for many birthdays to come.\n\n[**Give a gift!**](https://info.arxiv.org/about/donate.html)\n\n[Skip to main content](https://arxiv.org/abs/2207.06899#content)\n\n[![Image 3: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 4: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2207.06899 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 5: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 6: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Computer Vision and Pattern Recognition\n==========================================================\n\n**arXiv:2207.06899** (cs) \n\n [Submitted on 14 Jul 2022]\n\nTitle:Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation\n==============================================================================================\n\nAuthors:[Boming Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+B), [Bangbang Yang](https://arxiv.org/search/cs?searchtype=author&query=Yang,+B), [Zhenyang Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Z), [Zuoyue Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Z), [Guofeng Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+G), [Jiashu Zhao](https://arxiv.org/search/cs?searchtype=author&query=Zhao,+J), [Dawei Yin](https://arxiv.org/search/cs?searchtype=author&query=Yin,+D), [Zhaopeng Cui](https://arxiv.org/search/cs?searchtype=author&query=Cui,+Z), [Hujun Bao](https://arxiv.org/search/cs?searchtype=author&query=Bao,+H)\n\nView a PDF of the paper titled Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation, by Boming Zhao and 8 other authors\n\n[View PDF](https://arxiv.org/pdf/2207.06899)\n> Abstract:Expanding an existing tourist photo from a partially captured scene to a full scene is one of the desired experiences for photography applications. Although photo extrapolation has been well studied, it is much more challenging to extrapolate a photo (i.e., selfie) from a narrow field of view to a wider one while maintaining a similar visual style. In this paper, we propose a factorized neural re-rendering model to produce photorealistic novel views from cluttered outdoor Internet photo collections, which enables the applications including controllable scene re-rendering, photo extrapolation and even extrapolated 3D photo generation. Specifically, we first develop a novel factorized re-rendering pipeline to handle the ambiguity in the decomposition of geometry, appearance and illumination. We also propose a composited training strategy to tackle the unexpected occlusion in Internet images. Moreover, to enhance photo-realism when extrapolating tourist photographs, we propose a novel realism augmentation process to complement appearance details, which automatically propagates the texture details from a narrow captured photo to the extrapolated neural rendered image. The experiments and photo editing examples on outdoor scenes demonstrate the superior performance of our proposed method in both photo-realism and downstream applications.\n\nComments:Accepted to ACM Multimedia 2022. Project Page: [this https URL](https://zju3dv.github.io/neural_outdoor_rerender/)\nSubjects:Computer Vision and Pattern Recognition (cs.CV)\nCite as:[arXiv:2207.06899](https://arxiv.org/abs/2207.06899) [cs.CV]\n(or [arXiv:2207.06899v1](https://arxiv.org/abs/2207.06899v1) [cs.CV] for this version)\n[https://doi.org/10.48550/arXiv.2207.06899](https://doi.org/10.48550/arXiv.2207.06899)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\nRelated DOI:[https://doi.org/10.1145/3503161.3548125](https://doi.org/10.1145/3503161.3548125)\n\nFocus to learn more\n\n DOI(s) linking to related resources\n\nSubmission history\n------------------\n\n From: Bangbang Yang [[view email](https://arxiv.org/show-email/7d8db5c3/2207.06899)] \n\n**[v1]** Thu, 14 Jul 2022 13:28:08 UTC (30,574 KB)\n\n[](https://arxiv.org/abs/2207.06899)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled Factorized and Controllable Neural Re-Rendering of Outdoor Scene for Photo Extrapolation, by Boming Zhao and 8 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2207.06899)\n*   [TeX Source](https://arxiv.org/src/2207.06899)\n*   [Other Formats](https://arxiv.org/format/2207.06899)\n\n[![Image 7: license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.CV\n\n[<prev](https://arxiv.org/prevnext?id=2207.06899&function=prev&context=cs.CV \"previous in cs.CV (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2207.06899&function=next&context=cs.CV \"next in cs.CV (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.CV/new) | [recent](https://arxiv.org/list/cs.CV/recent) | [2022-07](https://arxiv.org/list/cs.CV/2022-07)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2207.06899?context=cs)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2207.06899)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2207.06899)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2207.06899)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2207.06899)\n\n### Bookmark\n\n[![Image 8: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2207.06899&description=Factorized%20and%20Controllable%20Neural%20Re-Rendering%20of%20Outdoor%20Scene%20for%20Photo%20Extrapolation \"Bookmark on BibSonomy\")[![Image 9: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2207.06899&title=Factorized%20and%20Controllable%20Neural%20Re-Rendering%20of%20Outdoor%20Scene%20for%20Photo%20Extrapolation \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2207.06899)\n*   [Venue](https://arxiv.org/abs/2207.06899)\n*   [Institution](https://arxiv.org/abs/2207.06899)\n*   [Topic](https://arxiv.org/abs/2207.06899)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2207.06899) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2208.01234": "Title: Flood Prediction Using Machine Learning Models\n\nURL Source: https://arxiv.org/abs/2208.01234\n\nMarkdown Content:\n[2208.01234] Flood Prediction Using Machine Learning Models\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2208.01234#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2208.01234 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Machine Learning\n===================================\n\n**arXiv:2208.01234** (cs) \n\n [Submitted on 2 Aug 2022]\n\nTitle:Flood Prediction Using Machine Learning Models\n====================================================\n\nAuthors:[Miah Mohammad Asif Syeed](https://arxiv.org/search/cs?searchtype=author&query=Syeed,+M+M+A), [Maisha Farzana](https://arxiv.org/search/cs?searchtype=author&query=Farzana,+M), [Ishadie Namir](https://arxiv.org/search/cs?searchtype=author&query=Namir,+I), [Ipshita Ishrar](https://arxiv.org/search/cs?searchtype=author&query=Ishrar,+I), [Meherin Hossain Nushra](https://arxiv.org/search/cs?searchtype=author&query=Nushra,+M+H), [Tanvir Rahman](https://arxiv.org/search/cs?searchtype=author&query=Rahman,+T)\n\nView a PDF of the paper titled Flood Prediction Using Machine Learning Models, by Miah Mohammad Asif Syeed and 5 other authors\n\n[View PDF](https://arxiv.org/pdf/2208.01234)\n> Abstract:Floods are one of nature's most catastrophic calamities which cause irreversible and immense damage to human life, agriculture, infrastructure and socio-economic system. Several studies on flood catastrophe management and flood forecasting systems have been conducted. The accurate prediction of the onset and progression of floods in real time is challenging. To estimate water levels and velocities across a large area, it is necessary to combine data with computationally demanding flood propagation models. This paper aims to reduce the extreme risks of this natural disaster and also contributes to policy suggestions by providing a prediction for floods using different machine learning models. This research will use Binary Logistic Regression, K-Nearest Neighbor (KNN), Support Vector Classifier (SVC) and Decision tree Classifier to provide an accurate prediction. With the outcome, a comparative analysis will be conducted to understand which model delivers a better accuracy.\n\nSubjects:Machine Learning (cs.LG)\nCite as:[arXiv:2208.01234](https://arxiv.org/abs/2208.01234) [cs.LG]\n(or [arXiv:2208.01234v1](https://arxiv.org/abs/2208.01234v1) [cs.LG] for this version)\n[https://doi.org/10.48550/arXiv.2208.01234](https://doi.org/10.48550/arXiv.2208.01234)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Tanvir Rahman [[view email](https://arxiv.org/show-email/f2ec641b/2208.01234)] \n\n**[v1]** Tue, 2 Aug 2022 03:59:43 UTC (1,064 KB)\n\n[](https://arxiv.org/abs/2208.01234)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled Flood Prediction Using Machine Learning Models, by Miah Mohammad Asif Syeed and 5 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2208.01234)\n*   [Other Formats](https://arxiv.org/format/2208.01234)\n\n[![Image 5: license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.LG\n\n[<prev](https://arxiv.org/prevnext?id=2208.01234&function=prev&context=cs.LG \"previous in cs.LG (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2208.01234&function=next&context=cs.LG \"next in cs.LG (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.LG/new) | [recent](https://arxiv.org/list/cs.LG/recent) | [2022-08](https://arxiv.org/list/cs.LG/2022-08)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2208.01234?context=cs)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2208.01234)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2208.01234)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2208.01234)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2208.01234)\n\n### Bookmark\n\n[![Image 6: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2208.01234&description=Flood%20Prediction%20Using%20Machine%20Learning%20Models \"Bookmark on BibSonomy\")[![Image 7: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2208.01234&title=Flood%20Prediction%20Using%20Machine%20Learning%20Models \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n- [x] IArxiv recommender toggle \n\nIArxiv Recommender _([What is IArxiv?](https://iarxiv.org/about))_\n\n*   [Author](https://arxiv.org/abs/2208.01234)\n*   [Venue](https://arxiv.org/abs/2208.01234)\n*   [Institution](https://arxiv.org/abs/2208.01234)\n*   [Topic](https://arxiv.org/abs/2208.01234)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2208.01234) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2209.01542": "Title: Recurrent Bilinear Optimization for Binary Neural Networks\n\nURL Source: https://arxiv.org/abs/2209.01542\n\nMarkdown Content:\n[2209.01542] Recurrent Bilinear Optimization for Binary Neural Networks\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2209.01542#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2209.01542 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Computer Vision and Pattern Recognition\n==========================================================\n\n**arXiv:2209.01542** (cs) \n\n [Submitted on 4 Sep 2022]\n\nTitle:Recurrent Bilinear Optimization for Binary Neural Networks\n================================================================\n\nAuthors:[Sheng Xu](https://arxiv.org/search/cs?searchtype=author&query=Xu,+S), [Yanjing Li](https://arxiv.org/search/cs?searchtype=author&query=Li,+Y), [Tiancheng Wang](https://arxiv.org/search/cs?searchtype=author&query=Wang,+T), [Teli Ma](https://arxiv.org/search/cs?searchtype=author&query=Ma,+T), [Baochang Zhang](https://arxiv.org/search/cs?searchtype=author&query=Zhang,+B), [Peng Gao](https://arxiv.org/search/cs?searchtype=author&query=Gao,+P), [Yu Qiao](https://arxiv.org/search/cs?searchtype=author&query=Qiao,+Y), [Jinhu Lv](https://arxiv.org/search/cs?searchtype=author&query=Lv,+J), [Guodong Guo](https://arxiv.org/search/cs?searchtype=author&query=Guo,+G)\n\nView a PDF of the paper titled Recurrent Bilinear Optimization for Binary Neural Networks, by Sheng Xu and 7 other authors\n\n[View PDF](https://arxiv.org/pdf/2209.01542)\n> Abstract:Binary Neural Networks (BNNs) show great promise for real-world embedded devices. As one of the critical steps to achieve a powerful BNN, the scale factor calculation plays an essential role in reducing the performance gap to their real-valued counterparts. However, existing BNNs neglect the intrinsic bilinear relationship of real-valued weights and scale factors, resulting in a sub-optimal model caused by an insufficient training process. To address this issue, Recurrent Bilinear Optimization is proposed to improve the learning process of BNNs (RBONNs) by associating the intrinsic bilinear variables in the back propagation process. Our work is the first attempt to optimize BNNs from the bilinear perspective. Specifically, we employ a recurrent optimization and Density-ReLU to sequentially backtrack the sparse real-valued weight filters, which will be sufficiently trained and reach their performance limits based on a controllable learning process. We obtain robust RBONNs, which show impressive performance over state-of-the-art BNNs on various models and datasets. Particularly, on the task of object detection, RBONNs have great generalization performance. Our code is open-sourced on [this https URL](https://github.com/SteveTsui/RBONN).\n\nComments:Accepted by ECCV 2022\nSubjects:Computer Vision and Pattern Recognition (cs.CV)\nCite as:[arXiv:2209.01542](https://arxiv.org/abs/2209.01542) [cs.CV]\n(or [arXiv:2209.01542v1](https://arxiv.org/abs/2209.01542v1) [cs.CV] for this version)\n[https://doi.org/10.48550/arXiv.2209.01542](https://doi.org/10.48550/arXiv.2209.01542)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Sheng Xu [[view email](https://arxiv.org/show-email/b8ab6fb1/2209.01542)] \n\n**[v1]** Sun, 4 Sep 2022 06:45:33 UTC (1,330 KB)\n\n[](https://arxiv.org/abs/2209.01542)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled Recurrent Bilinear Optimization for Binary Neural Networks, by Sheng Xu and 7 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2209.01542)\n*   [TeX Source](https://arxiv.org/src/2209.01542)\n*   [Other Formats](https://arxiv.org/format/2209.01542)\n\n[![Image 5: license icon](https://arxiv.org/icons/licenses/by-4.0.png)view license](http://creativecommons.org/licenses/by/4.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.CV\n\n[<prev](https://arxiv.org/prevnext?id=2209.01542&function=prev&context=cs.CV \"previous in cs.CV (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2209.01542&function=next&context=cs.CV \"next in cs.CV (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.CV/new) | [recent](https://arxiv.org/list/cs.CV/recent) | [2022-09](https://arxiv.org/list/cs.CV/2022-09)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2209.01542?context=cs)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2209.01542)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2209.01542)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2209.01542)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2209.01542)\n\n### Bookmark\n\n[![Image 6: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2209.01542&description=Recurrent%20Bilinear%20Optimization%20for%20Binary%20Neural%20Networks \"Bookmark on BibSonomy\")[![Image 7: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2209.01542&title=Recurrent%20Bilinear%20Optimization%20for%20Binary%20Neural%20Networks \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2209.01542)\n*   [Venue](https://arxiv.org/abs/2209.01542)\n*   [Institution](https://arxiv.org/abs/2209.01542)\n*   [Topic](https://arxiv.org/abs/2209.01542)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2209.01542) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2210.04325": "Title: ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models\n\nURL Source: https://arxiv.org/abs/2210.04325\n\nMarkdown Content:\n[2210.04325] ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models\n\n===============\n\n[Skip to main content](https://arxiv.org/abs/2210.04325#content)\n\n[![Image 1: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n\n[![Image 2: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)](https://arxiv.org/)>[cs](https://arxiv.org/list/cs/recent)> arXiv:2210.04325 \n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 3: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 4: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nComputer Science > Computation and Language\n===========================================\n\n**arXiv:2210.04325** (cs) \n\n [Submitted on 9 Oct 2022 ([v1](https://arxiv.org/abs/2210.04325v1)), last revised 22 Oct 2022 (this version, v3)]\n\nTitle:ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models\n=============================================================================\n\nAuthors:[Jiannan Xiang](https://arxiv.org/search/cs?searchtype=author&query=Xiang,+J), [Zhengzhong Liu](https://arxiv.org/search/cs?searchtype=author&query=Liu,+Z), [Yucheng Zhou](https://arxiv.org/search/cs?searchtype=author&query=Zhou,+Y), [Eric P. Xing](https://arxiv.org/search/cs?searchtype=author&query=Xing,+E+P), [Zhiting Hu](https://arxiv.org/search/cs?searchtype=author&query=Hu,+Z)\n\nView a PDF of the paper titled ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models, by Jiannan Xiang and 4 other authors\n\n[View PDF](https://arxiv.org/pdf/2210.04325)\n> Abstract:Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and convert each into a short sentence with reduced ambiguity. The sentence fusion stage then uses an LM like T5 to fuse all the resulting sentences into a coherent paragraph as the final description. We evaluate extensively on various datasets in different scenarios, including the zero-/few-/full-shot settings, and generalization to unseen predicates and out-of-domain data. Experimental results show that ASDOT consistently achieves significant improvement over baselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot setting.\n\nComments:Findings of EMNLP 2022\nSubjects:Computation and Language (cs.CL); Artificial Intelligence (cs.AI); Machine Learning (cs.LG)\nCite as:[arXiv:2210.04325](https://arxiv.org/abs/2210.04325) [cs.CL]\n(or [arXiv:2210.04325v3](https://arxiv.org/abs/2210.04325v3) [cs.CL] for this version)\n[https://doi.org/10.48550/arXiv.2210.04325](https://doi.org/10.48550/arXiv.2210.04325)\n\nFocus to learn more\n\n arXiv-issued DOI via DataCite\n\nSubmission history\n------------------\n\n From: Jiannan Xiang [[view email](https://arxiv.org/show-email/7acc41ba/2210.04325)] \n\n**[[v1]](https://arxiv.org/abs/2210.04325v1)** Sun, 9 Oct 2022 19:17:43 UTC (648 KB)\n\n**[[v2]](https://arxiv.org/abs/2210.04325v2)** Tue, 11 Oct 2022 03:33:06 UTC (648 KB)\n\n**[v3]** Sat, 22 Oct 2022 08:50:44 UTC (531 KB)\n\n[](https://arxiv.org/abs/2210.04325)Full-text links:\nAccess Paper:\n-------------\n\n View a PDF of the paper titled ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models, by Jiannan Xiang and 4 other authors\n\n*   [View PDF](https://arxiv.org/pdf/2210.04325)\n*   [TeX Source](https://arxiv.org/src/2210.04325)\n*   [Other Formats](https://arxiv.org/format/2210.04325)\n\n[view license](http://arxiv.org/licenses/nonexclusive-distrib/1.0/ \"Rights to this article\")\n\n Current browse context: \n\ncs.CL\n\n[<prev](https://arxiv.org/prevnext?id=2210.04325&function=prev&context=cs.CL \"previous in cs.CL (accesskey p)\") | [next>](https://arxiv.org/prevnext?id=2210.04325&function=next&context=cs.CL \"next in cs.CL (accesskey n)\")\n\n[new](https://arxiv.org/list/cs.CL/new) | [recent](https://arxiv.org/list/cs.CL/recent) | [2022-10](https://arxiv.org/list/cs.CL/2022-10)\n\n Change to browse by: \n\n[cs](https://arxiv.org/abs/2210.04325?context=cs)\n\n[cs.AI](https://arxiv.org/abs/2210.04325?context=cs.AI)\n\n[cs.LG](https://arxiv.org/abs/2210.04325?context=cs.LG)\n\n### References & Citations\n\n*   [NASA ADS](https://ui.adsabs.harvard.edu/abs/arXiv:2210.04325)\n*   [Google Scholar](https://scholar.google.com/scholar_lookup?arxiv_id=2210.04325)\n*   [Semantic Scholar](https://api.semanticscholar.org/arXiv:2210.04325)\n\n[a](https://arxiv.org/static/browse/0.3.4/css/cite.css)export BibTeX citation Loading...\n\nBibTeX formatted citation\n-------------------------\n\n×\n\nData provided by: [](https://arxiv.org/abs/2210.04325)\n\n### Bookmark\n\n[![Image 5: BibSonomy logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/bibsonomy.png)](http://www.bibsonomy.org/BibtexHandler?requTask=upload&url=https://arxiv.org/abs/2210.04325&description=ASDOT:%20Any-Shot%20Data-to-Text%20Generation%20with%20Pretrained%20Language%20Models \"Bookmark on BibSonomy\")[![Image 6: Reddit logo](https://arxiv.org/static/browse/0.3.4/images/icons/social/reddit.png)](https://reddit.com/submit?url=https://arxiv.org/abs/2210.04325&title=ASDOT:%20Any-Shot%20Data-to-Text%20Generation%20with%20Pretrained%20Language%20Models \"Bookmark on Reddit\")\n\nBibliographic Tools \n\nBibliographic and Citation Tools\n================================\n\n- [x] Bibliographic Explorer Toggle \n\nBibliographic Explorer _([What is the Explorer?](https://info.arxiv.org/labs/showcase.html#arxiv-bibliographic-explorer))_\n\n- [x] Connected Papers Toggle \n\nConnected Papers _([What is Connected Papers?](https://www.connectedpapers.com/about))_\n\n- [x] Litmaps Toggle \n\nLitmaps _([What is Litmaps?](https://www.litmaps.co/))_\n\n- [x] scite.ai Toggle \n\nscite Smart Citations _([What are Smart Citations?](https://www.scite.ai/))_\n\nCode, Data, Media \n\nCode, Data and Media Associated with this Article\n=================================================\n\n- [x] alphaXiv Toggle \n\nalphaXiv _([What is alphaXiv?](https://alphaxiv.org/))_\n\n- [x] Links to Code Toggle \n\nCatalyzeX Code Finder for Papers _([What is CatalyzeX?](https://www.catalyzex.com/))_\n\n- [x] DagsHub Toggle \n\nDagsHub _([What is DagsHub?](https://dagshub.com/))_\n\n- [x] GotitPub Toggle \n\nGotit.pub _([What is GotitPub?](http://gotit.pub/faq))_\n\n- [x] Huggingface Toggle \n\nHugging Face _([What is Huggingface?](https://huggingface.co/huggingface))_\n\n- [x] Links to Code Toggle \n\nPapers with Code _([What is Papers with Code?](https://paperswithcode.com/))_\n\n- [x] ScienceCast Toggle \n\nScienceCast _([What is ScienceCast?](https://sciencecast.org/welcome))_\n\nDemos \n\nDemos\n=====\n\n- [x] Replicate Toggle \n\nReplicate _([What is Replicate?](https://replicate.com/docs/arxiv/about))_\n\n- [x] Spaces Toggle \n\nHugging Face Spaces _([What is Spaces?](https://huggingface.co/docs/hub/spaces))_\n\n- [x] Spaces Toggle \n\nTXYZ.AI _([What is TXYZ.AI?](https://txyz.ai/))_\n\nRelated Papers \n\nRecommenders and Search Tools\n=============================\n\n- [x] Link to Influence Flower \n\nInfluence Flower _([What are Influence Flowers?](https://influencemap.cmlab.dev/))_\n\n- [x] Core recommender toggle \n\nCORE Recommender _([What is CORE?](https://core.ac.uk/services/recommender))_\n\n*   [Author](https://arxiv.org/abs/2210.04325)\n*   [Venue](https://arxiv.org/abs/2210.04325)\n*   [Institution](https://arxiv.org/abs/2210.04325)\n*   [Topic](https://arxiv.org/abs/2210.04325)\n\n About arXivLabs  \n\narXivLabs: experimental projects with community collaborators\n=============================================================\n\narXivLabs is a framework that allows collaborators to develop and share new arXiv features directly on our website.\n\nBoth individuals and organizations that work with arXivLabs have embraced and accepted our values of openness, community, excellence, and user data privacy. arXiv is committed to these values and only works with partners that adhere to them.\n\nHave an idea for a project that will add value for arXiv's community? [**Learn more about arXivLabs**](https://info.arxiv.org/labs/index.html).\n\n[Which authors of this paper are endorsers?](https://arxiv.org/auth/show-endorsers/2210.04325) | [Disable MathJax](javascript:setMathjaxCookie()) ([What is MathJax?](https://info.arxiv.org/help/mathjax.html)) \n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://arxiv.org/abs/2210.04325\",": "Title: [2210.04325\",] Article identifier not recognized\n\nURL Source: https://arxiv.org/abs/2210.04325%22,\n\nWarning: Target URL returned error 404: Not Found\n\nMarkdown Content:\n[2210.04325\",] Article identifier not recognized\n\n===============\n[![Image 1: close this message](https://arxiv.org/static/browse/0.3.4/images/icons/close-slider.png)](https://arxiv.org/abs/2210.04325%22,#)\n\n![Image 2: arXiv smileybones](https://arxiv.org/static/browse/0.3.4/images/icons/smileybones-pixel.png)\n\nHappy Birthday to arXiv!\n------------------------\n\nIt's our birthday — woohoo! On August 14th, 1991, the very first paper was submitted to arXiv. That's 34 years of open science! Give today and help support arXiv for many birthdays to come.\n\n[**Give a gift!**](https://info.arxiv.org/about/donate.html)\n\n[Skip to main content](https://arxiv.org/abs/2210.04325%22,#content)\n\n[![Image 3: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nWe gratefully acknowledge support from the Simons Foundation, [member institutions](https://info.arxiv.org/about/ourmembers.html), and all contributors.[Donate](https://info.arxiv.org/about/donate.html)\n\n[](https://arxiv.org/IgnoreMe)\n![Image 4: arxiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logo-one-color-white.svg)\n===================================================================================================\n\n[Help](https://info.arxiv.org/help) | [Advanced Search](https://arxiv.org/search/advanced)\n\nSearch\n\n[![Image 5: arXiv logo](https://arxiv.org/static/browse/0.3.4/images/arxiv-logomark-small-white.svg)](https://arxiv.org/)\n\n[![Image 6: Cornell University Logo](https://arxiv.org/static/browse/0.3.4/images/icons/cu/cornell-reduced-white-SMALL.svg)](https://www.cornell.edu/)\n\nGO\n\nquick links\n-----------\n\n*   [Login](https://arxiv.org/login)\n*   [Help Pages](https://info.arxiv.org/help)\n*   [About](https://info.arxiv.org/about)\n\nArticle identifier '2210.04325\",' not recognized\n================================================\n\nYou might instead try to [search for articles](https://arxiv.org/search) using title or author information.\n\nFor additional help on arXiv identifiers, see [understanding the arXiv identifier](https://info.arxiv.org/help/arxiv_identifier.html).\n\n*   [About](https://info.arxiv.org/about)\n*   [Help](https://info.arxiv.org/help)\n\n*   [Contact](https://info.arxiv.org/help/contact.html)\n*   [Subscribe](https://info.arxiv.org/help/subscribe)\n\n*   [Copyright](https://info.arxiv.org/help/license/index.html)\n*   [Privacy Policy](https://info.arxiv.org/help/policies/privacy_policy.html)\n\n*   [Web Accessibility Assistance](https://info.arxiv.org/help/web_accessibility.html)\n*   [arXiv Operational Status](https://status.arxiv.org/)\n\n Get status notifications via [email](https://subscribe.sorryapp.com/24846f03/email/new) or [slack](https://subscribe.sorryapp.com/24846f03/slack/new)\n",
  "https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/\",": "Title: Defining authorship in your research paper - Author Services\n\nURL Source: https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,\n\nMarkdown Content:\nDefining authorship in your research paper - Author Services\n\n===============\n\n[Skip to main content](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#main-content \"Skip to main content\")\n\n[![Image 4: Author Services Home](https://authorservices.taylorandfrancis.com/wp-content/themes/JTF-child/img/logo_tandf_as_icon.svg)![Image 5: Author Services Home](https://authorservices.taylorandfrancis.com/wp-content/themes/JTF-child/img/logo_tandf_as_icon.svg)](https://authorservices.taylorandfrancis.com/)\n*   [Search Author Services](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n*   [Publish](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Why publish with us?](https://www.tandfonline.com/why-publish-with-us)\n    *   [Find a journal](https://www.tandfonline.com/action/showPublications?pubType=journal)\n    *   [Search calls for papers](https://authorservices.taylorandfrancis.com/call-for-papers/)\n    *   [Journal Suggester](https://authorservices.taylorandfrancis.com/publishing-your-research/choosing-a-journal/journal-suggester/)\n    *   [Step-by-step guide](https://authorservices.taylorandfrancis.com/publishing-your-research/)\n    *   [Open access publishing](https://www.tandfonline.com/openaccess)\n    \nBrowse our journals\n\nHead to [Taylor & Francis Online](https://www.tandfonline.com/)\n\n[Go to Taylor & Francis Online](https://www.tandfonline.com/)\n\n*   [](https://authorservices.taylorandfrancis.com/ \"Menu item - Home\")\n*   Publish in a journal\n\n    *   Publishing your research        [![Image 6](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Choosing_a_journal_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/) \n[Steps to publication](https://authorservices.taylorandfrancis.com/publishing-your-research/)\n\nDiscover how to get your paper published, from choosing the right journal and understanding what a peer reviewed article is, to responding to reviewers and navigating the production process. [![Image 7](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Choosing_a_journal_2-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/choosing-a-journal/)  [Choosing a journal](https://authorservices.taylorandfrancis.com/publishing-your-research/choosing-a-journal/)\n\nChoosing a journal for your research can seem daunting, but it doesn’t need to be.   [![Image 8](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Writing_your_paper_2-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/)  [Writing your paper](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/)\n\nPublishing the results of your research is a critical part of your academic career.   [![Image 9](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Submission_2-edited-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/making-your-submission/)  [Making your submission](https://authorservices.taylorandfrancis.com/publishing-your-research/making-your-submission/)\n\nOnce you’ve chosen the right journal for your research and written your paper.   [![Image 10](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/Icon_peer_review-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/peer-review/)  [Peer review](https://authorservices.taylorandfrancis.com/publishing-your-research/peer-review/)\n\nThe peer review process starts once you have submitted your paper to a journal.   [![Image 11](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/Icon_production-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/moving-through-production/)  [Production](https://authorservices.taylorandfrancis.com/publishing-your-research/moving-through-production/)\n\nOnce your article has been accepted for publication, the next step is production.   [![Image 12](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/Icon_submission-mm_desktop.png)](https://authorservices.taylorandfrancis.com/publishing-your-research/after-publication/)  [After publication](https://authorservices.taylorandfrancis.com/publishing-your-research/after-publication/)\n\nYou may think that getting your paper published is the final step in the process, but there is more to be done.      \n    *   Research impact        [![Image 13](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Research_impact_9-mm_desktop.png)](https://authorservices.taylorandfrancis.com/research-impact/) \n[Research impact](https://authorservices.taylorandfrancis.com/research-impact/)\n\nResearch impact is an important topic in the research world. Use this guide to understand what impact means for you and your work, how to measure it, and how to increase it. [![Image 14](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Peer_review_2-mm_desktop.png)](https://authorservices.taylorandfrancis.com/research-impact/sharing-versions-of-journal-articles/) \n[Sharing versions of journal articles](https://authorservices.taylorandfrancis.com/research-impact/sharing-versions-of-journal-articles/)\n\nRead your research without barriers, and give other researchers greater opportunity to build upon your work. [![Image 15](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Writing_your_paper_3-mm_desktop.png)](https://authorservices.taylorandfrancis.com/research-impact/how-to-write-an-academic-blog-post/) \n[How to write an academic blog post](https://authorservices.taylorandfrancis.com/research-impact/how-to-write-an-academic-blog-post/)\n\nBlogs can be a great way for academic authors to reach audiences they might not otherwise have access to. [![Image 16](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Research_impact_7-mm_desktop.png)](https://authorservices.taylorandfrancis.com/research-impact/creating-a-video-abstract-for-your-research/) \n[Creating a video abstract for your research](https://authorservices.taylorandfrancis.com/research-impact/creating-a-video-abstract-for-your-research/)\n\nA video abstract lets you introduce readers to your article in your own words, telling others why they should read your research.    \n\n*   Publish your book\n\n    *   [Why publish with us?](https://authorservices.taylorandfrancis.com/publish-your-book/why-publish-with-taylor-and-francis/ \"Menu item - Why publish with us?\")\n    *   [Submit your book proposal](https://authorservices.taylorandfrancis.com/publish-your-book/submit-your-book-proposal/ \"Menu item - Submit your book proposal\")\n    *   [Writing & Editing Services](https://authorservices.taylorandfrancis.com/publish-your-book/writing-editing-services/ \"Menu item - Writing & Editing Services\")\n    *   [Marketing Services](https://authorservices.taylorandfrancis.com/publish-your-book/marketing-services/ \"Menu item - Marketing Services\")\n    *   [Author Discounts](https://authorservices.taylorandfrancis.com/publish-your-book/author-discount/ \"Menu item - Author Discounts\")\n\n*   Choosing open    [![Image 17](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Open_access_4-mm_desktop.png)](https://authorservices.taylorandfrancis.com/choose-open/) \n[Choosing open](https://authorservices.taylorandfrancis.com/choose-open/)\n\nAt Taylor & Francis we believe open research is the best way to increase the reach and impact of knowledge that can improve lives. [![Image 18](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Open_access_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/) \n[Choose open access when publishing your research](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/)\n\nRead your research without barriers, and give other researchers greater opportunity to build upon your work. [![Image 19](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Open_access_2-mm_desktop.png)](https://authorservices.taylorandfrancis.com/choose-open/open-data/) \n[Choosing Open Data](https://authorservices.taylorandfrancis.com/choose-open/open-data/)\n\nFrom the range of different options for sharing research data, an increasing number of researchers are choosing to make their data open. [Open access cost finder](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/open-access-cost-finder/)\n\nThe peer review process starts once you have submitted your paper to a journal.\n\n[Open access agreements](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/oa-agreements/)\n\nOnce your article has been accepted for publication, the next step is production.\n\n[Open access books](https://authorservices.taylorandfrancis.com/publish-your-book/why-publish-with-taylor-and-%20francis/publish-open-access-with-taylor-francis/)\n\nMake your book freely available to readers worldwide while maintaining the same high-quality peer review and production standards    \n*   Policies    [![Image 20](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Choosing_a_journal_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/data-sharing-policies/)  [![Image 21](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Research_impact_7-mm_desktop.png)](https://authorservices.taylorandfrancis.com/data-sharing-policies/)   \n[Understanding our data sharing policies](https://authorservices.taylorandfrancis.com/data-sharing-policies/)\n\nAre there data associated with the article you’re submitting to a Taylor & Francis journal? Over 2,000 Taylor & Francis journals have policies which state how these data should be shared.\n\n[Defining authorship in your research paper](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/)\n\nAuthorship gives credit and implies accountability for published work, so there are academic, social and financial implications.\n\n[What is conflict of interest?](https://authorservices.taylorandfrancis.com/editorial-policies/competing-interest/) [![Image 22](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Writing_your_paper_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/editorial-policies/)  [Taylor & Francis Editorial Policies](https://authorservices.taylorandfrancis.com/editorial-policies/)\n\nWhere a journal is owned by and published on behalf of a learned society or association, you should refer to any additional requirements set out by that journal.   [![Image 23](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Research_impact_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/data-sharing-policies/share-upon-reasonable-request/)  [Share upon reasonable request data sharing policy](https://authorservices.taylorandfrancis.com/data-sharing-policies/share-upon-reasonable-request/)\n\nMany Taylor & Francis journals have policies on data sharing which state how data associated with your article should be shared.   [![Image 24](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Events_4-mm_desktop.png)](https://authorservices.taylorandfrancis.com/data-sharing-policies/basic/)  [Basic data sharing policy](https://authorservices.taylorandfrancis.com/data-sharing-policies/basic/)\n\nMany Taylor & Francis journals have policies on data sharing which state how data associated with your article should be shared.      \n*   Researcher services\n\n    \n\n[Researcher services](https://authorservices.taylorandfrancis.com/researcher-services/)\n\n [![Image 25](https://authorservices.taylorandfrancis.com/wp-content/uploads/2024/08/illustration_Research_impact_1-mm_desktop.png)](https://authorservices.taylorandfrancis.com/researcher-services/)  \n\n[Manuscript preparation](https://authorservices.taylorandfrancis.com/researcher-services/preparing-your-article-for-submission/)\n\n        *   [English language editing](https://www.tandfeditingservices.com/services/)\n        *   [Scientific editing](https://www.tandfeditingservices.com/services/scientific-editing-services.html)\n        *   [Book editing](https://www.tandfeditingservices.com/services/book-editing-services.html)\n        *   [Translation](https://www.tandfeditingservices.com/services/translation.html)\n        *   [Manuscript formatting](https://www.tandfeditingservices.com/services/manuscript-formatting.html)\n        *   [Artwork preparation](https://www.tandfeditingservices.com/services/artwork-preparation.html)\n\n[Submission](https://authorservices.taylorandfrancis.com/researcher-services/journal-submission-support/)\n\n        *   [Similarity review report](https://www.tandfeditingservices.com/services/plagiarism-check.html)\n        *   [Pre-Submission Expert Review](https://www.tandfeditingservices.com/services/pre-submission-expert-review.html)\n        *   [Manuscript formatting](https://www.tandfeditingservices.com/services/manuscript-formatting.html)\n        *   [Scientific editing](https://www.tandfeditingservices.com/services/scientific-editing-services.html)\n\n[Research communication](https://authorservices.taylorandfrancis.com/researcher-services/your-research-paper-is-accepted-for-publication/)\n\n        *   [Lay summary](https://www.tandfeditingservices.com/services/lay-summary.html)\n        *   [Research impact summary](https://www.tandfeditingservices.com/services/research-impact-summary.html)\n        *   [Video highlight](https://www.tandfeditingservices.com/services/video-highlights.html)\n        *   [Headline infographic](https://www.tandfeditingservices.com/services/infographics.html)\n        *   [Research infographic](https://www.tandfeditingservices.com/services/infographics.html)\n\n*   [Events](https://authorservices.taylorandfrancis.com/events/ \"Menu item - Events\")\n*   [Insights blog](https://authorservices.taylorandfrancis.com/insights-blog/ \"Menu item - Insights blog\")\n\n*   [Publish in a journal](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Publishing your research](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n        *   [Steps to publication](https://authorservices.taylorandfrancis.com/publishing-your-research/)\n        *   [Choosing a journal](https://authorservices.taylorandfrancis.com/publishing-your-research/choosing-a-journal/)\n        *   [Writing your paper](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/)\n        *   [Making your submission](https://authorservices.taylorandfrancis.com/publishing-your-research/making-your-submission/)\n        *   [Peer review](https://authorservices.taylorandfrancis.com/publishing-your-research/peer-review/)\n        *   [Production](https://authorservices.taylorandfrancis.com/publishing-your-research/moving-through-production/)\n        *   [After publication](https://authorservices.taylorandfrancis.com/publishing-your-research/after-publication/)\n\n    *   [Research impact](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n        *   [Research impact](https://authorservices.taylorandfrancis.com/research-impact/)\n        *   [Sharing versions of journal articles](https://authorservices.taylorandfrancis.com/research-impact/sharing-versions-of-journal-articles/)\n        *   [How to write an academic blog post](https://authorservices.taylorandfrancis.com/research-impact/how-to-write-an-academic-blog-post/)\n        *   [Creating a video abstract for your research](https://authorservices.taylorandfrancis.com/research-impact/creating-a-video-abstract-for-your-research/)\n\n*   [Publish your book](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Why publish with Taylor & Francis?](https://authorservices.taylorandfrancis.com/publish-your-book/why-publish-with-taylor-and-francis/)\n    *   [Submit your book proposal](https://authorservices.taylorandfrancis.com/publish-your-book/submit-your-book-proposal/)\n    *   [Writing & Editing Services](https://authorservices.taylorandfrancis.com/publish-your-book/writing-editing-services/)\n    *   [Marketing Services](https://authorservices.taylorandfrancis.com/publish-your-book/marketing-services/)\n    *   [Author Discount](https://authorservices.taylorandfrancis.com/publish-your-book/author-discount/)\n\n*   [Choose Open](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Choose Open](https://authorservices.taylorandfrancis.com/choose-open/)\n    *   [Choose open access when publishing your research](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/)\n    *   [Choose Open Data](https://authorservices.taylorandfrancis.com/choose-open/open-data/)\n    *   [Open access cost finder](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/open-access-cost-finder/)\n    *   [Open access agreements information](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/oa-agreements/ \"Open access agreements\")\n\n*   [Policies](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Understanding our data sharing policies](https://authorservices.taylorandfrancis.com/data-sharing-policies/)\n    *   [Defining authorship in your research paper](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/)\n    *   [What is a competing interest?](https://authorservices.taylorandfrancis.com/editorial-policies/competing-interest/)\n    *   [Taylor & Francis Editorial Policies](https://authorservices.taylorandfrancis.com/editorial-policies/)\n    *   [Share upon reasonable request data sharing policy](https://authorservices.taylorandfrancis.com/data-sharing-policies/share-upon-reasonable-request/)\n    *   [Basic data sharing policy](https://authorservices.taylorandfrancis.com/data-sharing-policies/basic/)\n\n*   [Researcher Services](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n    *   [Manuscript preparation](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n        *   [Manuscript preparation](https://authorservices.taylorandfrancis.com/researcher-services/preparing-your-article-for-submission/)\n        *   [English language editing](https://www.tandfeditingservices.com/services/)\n        *   [Scientific editing](https://www.tandfeditingservices.com/services/scientific-editing-services.html)\n        *   [Book editing](https://www.tandfeditingservices.com/services/book-editing-services.html)\n        *   [Translation](https://www.tandfeditingservices.com/services/translation.html)\n        *   [Manuscript formatting](https://www.tandfeditingservices.com/services/manuscript-formatting.html)\n        *   [Artwork preparation](https://www.tandfeditingservices.com/services/artwork-preparation.html)\n\n    *   [Researcher communication](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n        *   [Research communication](https://authorservices.taylorandfrancis.com/researcher-services/your-research-paper-is-accepted-for-publication/)\n        *   [Lay summary](https://www.tandfeditingservices.com/services/lay-summary.html)\n        *   [Research impact summary](https://www.tandfeditingservices.com/services/research-impact-summary.html)\n        *   [Video highlight](https://www.tandfeditingservices.com/services/video-highlights.html)\n        *   [Headline infographic](https://www.tandfeditingservices.com/services/infographics.html)\n        *   [Research infographic](https://www.tandfeditingservices.com/services/infographics.html)\n\n    *   [Submission](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#)\n\n        *   [Submission](https://authorservices.taylorandfrancis.com/researcher-services/journal-submission-support/)\n        *   [Similarity review report](https://www.tandfeditingservices.com/services/plagiarism-check.html)\n        *   [Pre-Submission Expert Review](https://www.tandfeditingservices.com/services/pre-submission-expert-review.html \"Rapid technical review\")\n        *   [Manuscript formatting](https://www.tandfeditingservices.com/services/manuscript-formatting.html)\n        *   [Scientific editing](https://www.tandfeditingservices.com/services/scientific-editing-services.html)\n\n*   [Events for researchers](https://authorservices.taylorandfrancis.com/events/ \"Events\")\n*   [Insights blog](https://authorservices.taylorandfrancis.com/insights-blog/)\n*   [Go to Taylor & Francis Online](https://www.tandfonline.com/)\n\n*   [Home](https://authorservices.taylorandfrancis.com/ \"Author Services\")\n\n*   [Editorial Policies](https://authorservices.taylorandfrancis.com/editorial-policies/ \"Editorial Policies\")\n\n*   [Defining authorship in your research paper](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,)\n\nDefining authorship in your research paper\n==========================================\n\nCo-authors, corresponding authors, and affiliations\n---------------------------------------------------\n\nQuick links\n-----------\n\n*   [What does a co-author do?](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#coauthor)\n*   [Affiliations](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#affiliations)\n*   [Taylor & Francis editorial policies on authorship](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/%22,#editorial-policies)\n\nWhy does authorship matter?\n---------------------------\n\n_Play an audio reading of this section:_ Your browser does not support the audio tag.\n\nAuthorship gives credit and implies accountability for published work, so there are academic, social and financial implications.\n\nIt is very important to make sure people who have contributed to a paper, are given credit as authors. And also that people who are recognized as authors, understand their responsibility and accountability for what is being published.\n\nThere are a couple of types of authorship to be aware of.\n\n*   **Co-author**\n\nAny person who has made a significant contribution to a journal article. They also share responsibility and accountability for the results of the published research.\n\n*   **Corresponding author**\n\nIf more than one author writes an article, you’ll choose one person to be the corresponding author. This person will handle all correspondence about the article and sign the publishing agreement on behalf of all the authors. They are responsible for ensuring that all the authors’ contact details are correct, and agree on the order that their names will appear in the article. The authors also will need to make sure that affiliations are correct and are the same in both the manuscript and the submission system, as explained in more detail below. The corresponding author must also take responsibility for any applicable article publishing charges (APCs). Eligibility for waivers and open access agreements is determined by the affiliation of the corresponding author, which cannot be changed after submission.\n\nOpen access publishing\n----------------------\n\nThere is increasing pressure on researchers to show the societal impact of their research.\n\nOpen access can help your work reach new readers, beyond those with easy access to a research library.\n\n[Find out more](https://authorservices.taylorandfrancis.com/choose-open/publishing-open-access/ \" Find out more \")\n\nHow common is co-authorship and what are the challenges collaborating authors face? Our white paper[Co-authorship in the Humanities and Social Sciences: A global view](https://authorservices.taylorandfrancis.com/wp-content/uploads/2017/09/Coauthorship-white-paper.pdf) explores the experiences of 894 researchers from 62 countries.\n\nIf you are a named co-author, this means that you:\n--------------------------------------------------\n\n_Play an audio reading of this section:_ Your browser does not support the audio tag.\n\n1.   Made a significant contribution to the work reported. That could be in the conception, study design, execution, acquisition of data, analysis and interpretation, or in all these areas; AND\n\n2.   Have drafted or written, substantially revised or critically reviewed the article; AND\n\n3.   Have agreed on the journal to which the article will be submitted; AND\n\n4.   Reviewed and agreed on all versions of the article before submission, during revision, the final version accepted for publication, and any significant changes introduced at the proofing stage; AND\n\n5.   Agree to take responsibility and be accountable for the contents of the article. Share responsibility to resolve any questions raised about the accuracy or integrity of the published work.\n\n![Image 26](https://authorservices.taylorandfrancis.com/wp-content/uploads/2022/11/Research_impact_2-300x225.png)\n\nEvery submission to our medical and health science journals should comply with the International Committee on Medical Journal Ethics’[definition of authorship](http://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html).\n\nPlease include any other form of specific personal contribution in the acknowledgments section of your paper.\n\nAffiliations: get it right\n--------------------------\n\n_Play an audio reading of this section:_ Your browser does not support the audio tag.\n\nYour affiliation in the manuscript and when entered into the submission system should be the institution where you conducted the research. You should also include details of any funding received from that institution.\n\nIf you have changed affiliation since completing the research, your new affiliation can be acknowledged in a note. We can’t normally make changes to affiliation after the journal accepts your article, and we are unable to change affiliation to achieve eligibility for an open access agreement.\n\nAuthor contributions\n--------------------\n\nPromoting transparency in author contributions makes sure that appropriate credit for specific aspects of published work can be clearly attributed to each author. To enable authors to state the individual contributions of each listed author on the article, many T&F journals have adopted [Contributor Roles Taxonomy (CRediT)](https://authorservices.taylorandfrancis.com/editorial-policies/credit-at-taylor-francis/),which allows individual contributions to be listed according to specific role types.\n\n![Image 27: Vector illustration of a female character holding a large magnifying glass and smiling.](https://authorservices.taylorandfrancis.com/wp-content/uploads/2022/11/Peer_review_11-e1689942960421-300x468.png)\n\nChanges to authorship\n---------------------\n\n*   Authorship changes post-submission should only be made in exceptional circumstances, and any requests for authors to be removed or added must be in line with our authorship criteria.\n\n*   If you need to make an authorship change, you will need to contact the Journal Editorial Office or Editorial team in the first instance. You will be asked to complete our [Authorship Change request form](https://files.taylorandfrancis.com/change%20of%20authorship%20request%20form.docx); all authors (including those you are adding or removing) must sign this form. This will be reviewed by the Editor (and in some instances, the publisher).\n\n*   Please note any authorship change is at the Editor’s discretion; they have the right to refuse any authorship change they do not believe conforms with our authorship policies.\n\n*   Some T&F journals do not allow **any** authorship changes post-submission; where this is applicable, this will be clearly indicated on the journal homepage or on the ‘instructions for authors’ page.\n\n*   If you wish to make a change to the corresponding author before the article is published (for example, if a co-author becomes the corresponding author), you will need to contact the Journal Editorial Office or the production editor. You will need to confirm to them that both authors have agreed the change. Note that it is not possible to change corresponding author to achieve eligibility for an APC waiver or open access agreement.\n\n*   Requested changes to the co-authors or corresponding authors following publication of the article may be considered, in line with the[**authorship guidelines issued by COPE**](https://publicationethics.org/authorship), the Committee on Publication Ethics. Please[**see our corrections policy**](https://authorservices.taylorandfrancis.com/publishing-your-research/after-publication/corrections-to-published-articles/)for more details. Any requests for changes must be made by submitting the completed[**Authorship Change Request form**](https://files.taylorandfrancis.com/change%20of%20authorship%20request%20form.docx).\n\nAuthorship Change Request form\n------------------------------\n\n[Download the form](https://files.taylorandfrancis.com/change%20of%20authorship%20request%20form.docx \" Download the form \")\n\nImportant: agree on your corresponding author and the order of co-authors, and check all affiliations and contact details before submitting.\n\nTaylor & Francis Editorial Policies on Authorship\n-------------------------------------------------\n\nThe following instructions (part of our[Editorial Policies](https://authorservices.taylorandfrancis.com/editorial-policies/)) apply to all Taylor & Francis Group journals.\n\nAI-based tools and technologies for content generation\n------------------------------------------------------\n\nIf you have used AI tools (e.g. large language models, generative AI, and chatbots) in your research or the writing of your article, please note the following authorship principles:\n\n**You must not list AI tools as a co-author of your article**. This is because authorship requires taking accountability for content, consenting to publication via a publishing agreement, and giving contractual assurances about the integrity of the work. These are uniquely human responsibilities that cannot be undertaken by AI tools.\n\n**You must clearly acknowledge within your article use of Generative AI tools**. Please add a statement in the Methods or Acknowledgments section which includes:\n\n*   The full name of the tool used (with version number).\n\n*   How it was used.\n\n*   The reason for use.\n\nWhen you submit your work to a Taylor & Francis journal you may be asked to confirm that you have disclosed within your manuscript any use of AI tools. This level of transparency makes sure that editors and reviewers are aware that AI tools have been used, so that they can assess whether they have been used appropriately and responsibly.\n\nPlease see the [Taylor & Francis AI Policy](https://taylorandfrancis.com/our-policies/ai-policy/) for more details.\n\nCorresponding author\n--------------------\n\nCo-authors must agree on who will take on the role of corresponding author. It is then the responsibility of the corresponding author to reach consensus with all co-authors regarding all aspects of the article, prior to submission. This includes the authorship list and order, and list of correct affiliations.\n\nThe corresponding author is also responsible for liaising with co-authors regarding any editorial queries. And, they act on behalf of all co-authors in any communication about the article throughout: submission, peer review, production, and after publication. The corresponding author signs the publishing agreement on behalf of all the listed authors, and takes responsibility for any applicable APC.\n\nPatient authors\n---------------\n\nTaylor & Francis is dedicated to collaborating with patients, their carers and their support communities. Through the publication of [plain language summaries](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/how-to-write-a-plain-language-summary/) (short, jargon-free summary within an article after its abstract) and [plain language summary of publications](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/how-to-write-a-plain-language-summary/) (a standalone, jargon-free and visual summary of an article) across our journals, we have been able to connect with patient reviewers and patient organizations to ensure that the research we publish strengthens clinical care for those who need it the most. We believe that patient involvement in scholarly publications can help to achieve this and welcome patients as authors on selected [Medicine, Dentistry, Nursing & Allied Health journals](https://www.tandfonline.com/topic/allsubjects/me?startPage=&target=titleSearch&content=title) on several article types. Information about whether a journal considers patient authors, will be available on the Instructions for Authors page of the journal.\n\n**Patient authors should fulfil the following criteria:**\n\n*   A person who lives with or is affected by a disease or condition (i.e., a broad definition of patient that includes those with lived conditions or receiving health or social care, caregivers, family members and members of patient advocacy groups who represent them).\n\n*   A person who provides unique and valuable input from their personal patient perspective to the publication.\n\n*   A person who meets all the criteria required for authorship, as listed above and as per the International Committee on Medical Journal Ethics’ [definition of authorship](https://www.icmje.org/recommendations/browse/roles-and-responsibilities/defining-the-role-of-authors-and-contributors.html) and the [Taylor & Francis authorship policies](https://authorservices.taylorandfrancis.com/editorial-policies/defining-authorship-research-paper/).\n\nFor more information on patient authorship, please visit our [guidance for patient authors](https://authorservices.taylorandfrancis.com/editorial-policies/guidance-for-patient-authors/).\n\nAnonymous authorship and researchers at risk\n--------------------------------------------\n\nWhere there is a credible risk of serious harm or threat to their life or liberty, as a result of their research or findings, researchers should contact the journal Editor or editorial office to discuss what options for publication may be available to minimise risk to the researcher.\n\nPlease note that the purpose of naming authors on scholarly publications is to ensure that the appropriate individuals receive recognition, and are accountable, for the published work. Therefore, anonymous publication may only be considered in exceptional circumstances. Requests will be evaluated on their own merit by the journal Editor and Publisher, and an editorial note or footnote to accompany the publication may be warranted. The Editor and Publisher have full and sole discretion as to whether a request to publish anonymously will be granted and do not provide any guarantee that requests will be granted.\n\nIf the Editor and Publisher grants a request to publish anonymously, they cannot and do not make any guarantees with respect to the author’s total anonymity and the author acknowledges that they proceed with publication of the article at their own risk. The Publisher will also require the author to enter into any requisite publishing agreements and copyright documentation under the author’s legal name.\n\n**For further information on researchers at risk we recommend the following organisations:**\n\n*   [Scholars at Risk](https://www.scholarsatrisk.org/)\n\n*   [Cara (the Council for At-Risk Academics)](https://www.cara.ngo/)\n\n*   [IIE Scholar Rescue Fund](https://www.scholarrescuefund.org/)\n\nShould you have any further questions regarding this policy, please contact [ethics@tandf.co.uk](mailto:ethics@tandf.co.uk).\n\nChanges in authorship\n---------------------\n\nAny changes in authorship prior to or after publication must be agreed upon by all authors – including those authors being added or removed. It is the responsibility of the corresponding author to obtain confirmation from all co-authors and to provide a completed [Authorship Change Request form](https://files.taylorandfrancis.com/change%20of%20authorship%20request%20form.docx) to the editorial office.\n\nIf a change in authorship is necessary after publication, this will be amended via a post-publication notice. Any changes in authorship must comply with our criteria for authorship. And requests for significant changes to the authorship list, after the article has been accepted, may be rejected if clear reasons and evidence of author contributions cannot be provided. Note that it is not possible to change corresponding author to achieve eligibility for an APC waiver or open access agreement.\n\nAssistance from scientific, medical, technical writers or translators\n---------------------------------------------------------------------\n\nContributions made by professional scientific, medical or technical writers, translators or anyone who has assisted with the manuscript content, must be acknowledged. Their source of funding must also be declared.\n\nThey should be included in an ‘Acknowledgments’ section with an explanation of their role,or they should be included in the author list if appropriate.\n\nAuthors are advised to consult the[joint position statement](https://www.ismpp.org/assets/docs/Inititives/amwa-emwa-ismpp%20joint%20position%20statement%20on%20the%20role%20of%20professional%20medical%20writers_january%202017.pdf)from American Medical Writers Association (AMWA), European Medical Writers Association (EMWA), and International Society of Medical Publication Professionals (ISMPP).\n\nAssistance with experiments and data analysis\n---------------------------------------------\n\nAny significant contribution to the research reported, should be appropriately credited according to our authorship criteria.\n\nIf any parts of the research were outsourced to professional laboratories or to data analysts, this should be clearly stated within the manuscript, alongside an explanation of their role. Or, they should be included in the author list if appropriate.\n\nAuthors are responsible for retaining all of the original data related to their work, and should be prepared to share it with the journal editorial office if requested.\n\n![Image 28: Vector illustration of a bar chart, smallest bar is blue on the left, the tallest bar is pink in the middle, and the right bar is blue and is the middle tallest.](https://authorservices.taylorandfrancis.com/wp-content/uploads/2022/10/Research_impact_3-300x341.png)\n\nAcknowledgments\n---------------\n\nAny individuals who have contributed to the article (for example, technical assistance,formatting-related writing assistance, translators, scholarly discussions which significantly contributed to developing the article), but who do not meet the criteria for authorship, should be listed by name and affiliation in an ‘Acknowledgments’ section.\n\nIt is the responsibility of the authors to notify and obtain permission from those they wish to identify in this section. The process of obtaining permission should include sharing the article, so that those being identified can verify the context in which their contribution is being acknowledged.\n\nAny assistance from AI tools for content generation (e.g. large language models) and other similar types of technical tools which generate article content, **must**be clearly acknowledged within the article. It is the responsibility of authors to ensure the validity, originality and integrity of their article content. Authors are expected to use these types of tools responsibly and in accordance with our editorial policies on authorship and principles of publishing ethics.\n\nBiographical note\n-----------------\n\nPlease supply a short biographical note for each author. This could be adapted from your departmental website or academic networking profile and should be relatively brief (e.g. no more than 200 words).Authors are responsible for retaining all of the original data related to their work, and should be prepared to share it with the journal editorial office if requested.\n\n![Image 29: Vector illustration of a character sat down, wearing blue top and black skirt, smiling and looking through a pink telescope.](https://authorservices.taylorandfrancis.com/wp-content/uploads/2022/10/Publication_11-300x338.png)\n\nAuthor name changes on published articles\n-----------------------------------------\n\nThere are many reasons why an author may change their name in the course of their career. And they may wish to update their published articles to reflect this change, without publicly announcing this through a correction notice. Taylor & Francis will update journal articles where an author makes a request for their own name change, full or partial, without the requirement for an accompanying correction notice. Any pronouns in accompanying author bios and declaration statements will also be updated as part of the name change, if required.\n\nWhen an author requests a name change, Taylor & Francis will:\n\n*   Change the metadata associated with the article on our [Taylor & Francis Online](https://www.tandfonline.com/) platform.\n\n*   Update the HTML and PDF version of the article.\n\n*   Resupply the new metadata and article content to any abstracting and indexing services that have agreements with the journal. Note: such services may have their own bibliographic policies regarding author name changes. Taylor \\u0026amp; Francis cannot be held responsible for controlling updates to articles on third party sites and services once an article has been disseminated.\n\nIf an author wishes for a correction notice to be published alongside their name change, Taylor & Francis will accommodate this on request. But, it is not required for an author name change to be made.\n\nTo request a name change, please contact your Journal’s Production Editor or [contact us.](https://authorservices.taylorandfrancis.com/contact/)\n\nTaylor & Francis consider it a breach of publication ethics to request a name change for an individual without their explicit consent.\n\n![Image 30: Vector illustration showing five journals on a screen with one selected.](https://authorservices.taylorandfrancis.com/wp-content/uploads/2022/11/Choosing_a_journal_3-300x180.png)\n\nAdditional resources\n--------------------\n\n*   **[Co-authorship in the Humanities and Social Sciences](https://authorservices.taylorandfrancis.com/wp-content/uploads/2017/09/Coauthorship-white-paper.pdf)**– our white paper based on a global survey of researchers’ experiences of collaboration.\n\n*   **[Discussion Document: Authorship](https://publicationethics.org/resources/discussion-documents/discussion-document-authorship)**– produced by COPE (Committee on Publication Ethics), this updated guide includes practical advice on addressing the most common ethical issues in this area\n\n*   [**Taylor & Francis Editorial Policies**](https://authorservices.taylorandfrancis.com/editorial-policies/)\n\n*   [**Ethics for authors**](https://authorservices.taylorandfrancis.com/publishing-your-research/writing-your-paper/ethics-for-journal-authors/)– guidelines, support, and your checklist.\n\n[Contact us Contact us](https://authorservices.taylorandfrancis.com/contact/)\n\n*   [Cookie Policy](https://authorservices.taylorandfrancis.com/cookie-list/)\n*   [Privacy Policy](https://www.informa.com/privacy-policy/)\n*   [Terms & Conditions](https://authorservices.taylorandfrancis.com/terms-conditions/)\n*   [Accessibility](https://authorservices.taylorandfrancis.com/accessibility/)\n*   [Editorial Policies](https://authorservices.taylorandfrancis.com/editorial-policies/)\n*   [Contact us](https://authorservices.taylorandfrancis.com/contact/)\n\n*   [Taylor & Francis Online](https://www.tandfonline.com/ \"Link – Taylor & Francis Online\")\n*   [F1000 Research](https://f1000research.com/ \"Link – F1000 Research\")\n*   [Editing Services](https://www.tandfeditingservices.com/ \"Link – Editing Services\")\n*   [Editor Resources](https://editorresources.taylorandfrancis.com/ \"Link – Editor Resources\")\n*   [For Books Authors](https://www.routledge.com/resources/authors \"Link – For Books Authors\")\n\n[](https://www.facebook.com/TaylorandFrancisGroup)[](https://twitter.com/tandfonline)[](https://bsky.app/profile/tandfresearch.bsky.social)[](https://www.instagram.com/tandfresearch)[](https://www.youtube.com/channel/UC25r5M26suFU_87CieE1q9g)\n\n © 2025 Informa UK Limited, an [Informa Group](https://informa.com/) Company. Registered office is 5 Howick Place, London, SW1P 1WG. \n\nRegistered in England and Wales Number 1072954. Registered for VAT: GB 365 4626 36. ![Image 31: Taylor & Francis Group logo](https://authorservices.taylorandfrancis.com/wp-content/themes/JTF3/img/tfgroup-logo-rev.svg)\n\nNotifications\n\n![Image 33](https://t.co/1/i/adsct?bci=4&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=3&event=%7B%7D&event_id=f7e9a037-2beb-4a79-b4a6-f2e4b929284e&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=65f3c8a5-726f-4110-8028-1910e127149b&tw_document_href=https%3A%2F%2Fauthorservices.taylorandfrancis.com%2Feditorial-policies%2Fdefining-authorship-research-paper%2F&tw_iframe_status=0&txn_id=o0iah&type=javascript&version=2.3.33)![Image 34](https://analytics.twitter.com/1/i/adsct?bci=4&dv=UTC%26en-US%26Google%20Inc.%26Linux%20x86_64%26255%26800%26600%264%2624%26800%26600%260%26na&eci=3&event=%7B%7D&event_id=f7e9a037-2beb-4a79-b4a6-f2e4b929284e&integration=gtm&p_id=Twitter&p_user_id=0&pl_id=65f3c8a5-726f-4110-8028-1910e127149b&tw_document_href=https%3A%2F%2Fauthorservices.taylorandfrancis.com%2Feditorial-policies%2Fdefining-authorship-research-paper%2F&tw_iframe_status=0&txn_id=o0iah&type=javascript&version=2.3.33)\n",
  "https://royalsociety.org/journals/authors/author-guidelines/\",": "Title: Server Error in '/' Application.\n\nURL Source: https://royalsociety.org/journals/authors/author-guidelines/%22,\n\nWarning: Target URL returned error 500: Internal Server Error\n\nMarkdown Content:\n**Description:**An application error occurred on the server. The current custom error settings for this application prevent the details of the application error from being viewed remotely (for security reasons). It could, however, be viewed by browsers running on the local server machine. \n**Details:** To enable the details of this specific error message to be viewable on remote machines, please create a <customErrors> tag within a \"web.config\" configuration file located in the root directory of the current web application. This <customErrors> tag should then have its \"mode\" attribute set to \"Off\".\n\n```\n<!-- Web.Config Configuration File -->\n\n<configuration>\n    <system.web>\n        <customErrors mode=\"Off\"/>\n    </system.web>\n</configuration>\n```\n\n**Notes:** The current error page you are seeing can be replaced by a custom error page by modifying the \"defaultRedirect\" attribute of the application's <customErrors> configuration tag to point to a custom error page URL.\n```\n<!-- Web.Config Configuration File -->\n\n<configuration>\n    <system.web>\n        <customErrors mode=\"RemoteOnly\" defaultRedirect=\"mycustompage.htm\"/>\n    </system.web>\n</configuration>\n```\n"
}